{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#predicting-states-beyond-t+1\" data-toc-modified-id=\"predicting-states-beyond-t+1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>predicting states beyond t+1</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting states beyond t+1\n",
    "The scalar predictors I've worked through so far predict outputs at \"t+1\". They predict 'what comes immediately next' and return one time-state to do so.\n",
    "\n",
    "I'm awfully curious about returning t+2, t+3, so on, because:\n",
    "- It should be possible, since we have TM looking at t-1, t-... -> t-cells_per_column\n",
    "- It's been done! Intelletic looks 15 'bars' into the future, as per their product description, and I interpreted this as 'looking 15 states into the future'.\n",
    "    - this makes a lot of sense: you don't just want the stock price t+1, or the next 5 minutes from now. You want a _range_ and _probability_, which the anomaly-categorization model does quite nicely.\n",
    "- Our brains don't just look at one timestate in the future. Or do they? See below post.\n",
    "    - When you see 'football incoming towards my face', your brain outputs 'collision imminent' and associates it with 'pain', which kicks off 'avoid football' routine.\n",
    "        - is this your brain predicting several states (football approaching, impact, pain) after t=0? or running several consecutive calculations, each taking the former output as the new input?\n",
    "        - something tells me it's the second\n",
    "\n",
    "So how exactly is it done? I stumbled on a thread on the forums detailing one example (https://discourse.numenta.org/t/how-temporal-pooler-make-t-n-predictions-if-his-operate-only-t-t-1-timeframes/7826/2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "the TM algorithm alone is only able to make a prediction one time step into the future. This is to match how the connections work in biology. But to make HTM useful in practical ML applications, a lot of non-biological components are thrown into the mix. One of these is the ability to predict further into the future that t+1.\n",
    "\n",
    "There are a few different ways to implement this. One way is to hold a table of running averages on each cell for activity at “t+n” after that cell was active (where “n” is determined ahead of time). Since each cell is part of a high-order context, this works quite well (you are NOT asking “what is most likely to happen 25 timesteps after note G”, but something much more specific like \"what is most likely to happen 25 timesteps after the 357th note of Bethoven’s 5th.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
