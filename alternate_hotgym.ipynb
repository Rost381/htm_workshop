{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-up-&amp;-recoding-hotgym.py-so-i-can-figure-out-how-it-works\" data-toc-modified-id=\"Cleaning-up-&amp;-recoding-hotgym.py-so-i-can-figure-out-how-it-works-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning up &amp; recoding hotgym.py so i can figure out how it works</a></span><ul class=\"toc-item\"><li><span><a href=\"#default-parameter-dict\" data-toc-modified-id=\"default-parameter-dict-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>default parameter dict</a></span><ul class=\"toc-item\"><li><span><a href=\"#i'm-gonna-try-to-recode-this-without-&quot;def-main()&quot;-etc\" data-toc-modified-id=\"i'm-gonna-try-to-recode-this-without-&quot;def-main()&quot;-etc-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>i'm gonna try to recode this without \"def main()\" etc</a></span></li><li><span><a href=\"#read-input-file\" data-toc-modified-id=\"read-input-file-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>read input file</a></span></li><li><span><a href=\"#create-Encoder!\" data-toc-modified-id=\"create-Encoder!-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>create Encoder!</a></span></li><li><span><a href=\"#create-spatial-pooler\" data-toc-modified-id=\"create-spatial-pooler-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>create spatial pooler</a></span></li></ul></li><li><span><a href=\"#TM-parameter-notes:\" data-toc-modified-id=\"TM-parameter-notes:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>TM parameter notes:</a></span><ul class=\"toc-item\"><li><span><a href=\"#setup-likelihood-/-anomaly-thresholds\" data-toc-modified-id=\"setup-likelihood-/-anomaly-thresholds-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>setup likelihood / anomaly thresholds</a></span></li><li><span><a href=\"#iterate-through-dataset,-recording-inputs-&amp;-outputs\" data-toc-modified-id=\"iterate-through-dataset,-recording-inputs-&amp;-outputs-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>iterate through dataset, recording inputs &amp; outputs</a></span></li></ul></li></ul></li><li><span><a href=\"#alternate-idea:-what-if-we-just-run-a-.learn()-cycle-once-with-no-infer?\" data-toc-modified-id=\"alternate-idea:-what-if-we-just-run-a-.learn()-cycle-once-with-no-infer?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>alternate idea: what if we just run a .learn() cycle once with no infer?</a></span><ul class=\"toc-item\"><li><span><a href=\"#right,-that-ran.-surprising,-but-it-ran.-shall-we-try-running-the-original-loop-with-the-same-predictor-object-now?\" data-toc-modified-id=\"right,-that-ran.-surprising,-but-it-ran.-shall-we-try-running-the-original-loop-with-the-same-predictor-object-now?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>right, that ran. surprising, but it ran. shall we try running the original loop with the same predictor object now?</a></span></li></ul></li><li><span><a href=\"#new-error!-that-means-progress\" data-toc-modified-id=\"new-error!-that-means-progress-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>new error! that means progress</a></span><ul class=\"toc-item\"><li><span><a href=\"#alright,-what's-going-on-with-division-by-0-?\" data-toc-modified-id=\"alright,-what's-going-on-with-division-by-0-?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>alright, what's going on with division by 0 ?</a></span></li><li><span><a href=\"#ah,-we're-still-stuck-at-the-same-error-as-before\" data-toc-modified-id=\"ah,-we're-still-stuck-at-the-same-error-as-before-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>ah, we're still stuck at the same error as before</a></span><ul class=\"toc-item\"><li><span><a href=\"#something's-written-wrong,-i-think---or-i've-installed-something-wrong\" data-toc-modified-id=\"something's-written-wrong,-i-think---or-i've-installed-something-wrong-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>something's written wrong, i think - or i've installed something wrong</a></span></li><li><span><a href=\"#some-progress:\" data-toc-modified-id=\"some-progress:-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>some progress:</a></span></li></ul></li><li><span><a href=\"#why-do-we-call-predictor.infer(tm_SDR),-then-predictor.learn(count,-TM_SDR,-consumption/predictor_resolution)-at-each-iteration?\" data-toc-modified-id=\"why-do-we-call-predictor.infer(tm_SDR),-then-predictor.learn(count,-TM_SDR,-consumption/predictor_resolution)-at-each-iteration?-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>why do we call predictor.infer(tm_SDR), then predictor.learn(count, TM_SDR, consumption/predictor_resolution) at each iteration?</a></span><ul class=\"toc-item\"><li><span><a href=\"#because-we're-trying-to-make-a-prediction-on-each-round-to-see-how-well-we-grow-over-time\" data-toc-modified-id=\"because-we're-trying-to-make-a-prediction-on-each-round-to-see-how-well-we-grow-over-time-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>because we're trying to make a prediction on each round to see how well we grow over time</a></span><ul class=\"toc-item\"><li><span><a href=\"#makes-sense.-but\" data-toc-modified-id=\"makes-sense.-but-3.3.1.1\"><span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>makes sense. but</a></span></li></ul></li></ul></li><li><span><a href=\"#post-training\" data-toc-modified-id=\"post-training-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>post-training</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up & recoding hotgym.py so i can figure out how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "from htm.bindings.sdr import SDR, Metrics\n",
    "from htm.encoders.rdse import RDSE, RDSE_Parameters\n",
    "from htm.encoders.date import DateEncoder\n",
    "from htm.bindings.algorithms import SpatialPooler\n",
    "from htm.bindings.algorithms import TemporalMemory\n",
    "from htm.algorithms.anomaly_likelihood import AnomalyLikelihood #FIXME use TM.anomaly instead, but it gives worse results than the py.AnomalyLikelihood now\n",
    "from htm.bindings.algorithms import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mark/Documents/flatiron/projects/htm/htm_nlp_predictive/gymdata.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "input_file_path = cwd+'/gymdata.csv'\n",
    "input_file_path\n",
    "# _INPUT_FILE_PATH = os.join(cwd, 'gymdata.csv') # i moved this locally from the example folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default parameter dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "  # there are 2 (3) encoders: \"value\" (RDSE) & \"time\" (DateTime weekend, timeOfDay)\n",
    " 'enc': {\n",
    "      \"value\" :\n",
    "         {'resolution': 0.88, 'size': 700, 'sparsity': 0.02},\n",
    "      \"time\": \n",
    "         {'timeOfDay': (30, 1), 'weekend': 21}\n",
    " },\n",
    " 'predictor': {'sdrc_alpha': 0.1},\n",
    " 'sp': {'boostStrength': 3.0,\n",
    "        'columnCount': 1638,\n",
    "        'localAreaDensity': 0.04395604395604396,\n",
    "        'potentialPct': 0.85,\n",
    "        'synPermActiveInc': 0.04,\n",
    "        'synPermConnected': 0.13999999999999999,\n",
    "        'synPermInactiveDec': 0.006},\n",
    " 'tm': {'activationThreshold': 17,\n",
    "        'cellsPerColumn': 13,\n",
    "        'initialPerm': 0.21,\n",
    "        'maxSegmentsPerCell': 128,\n",
    "        'maxSynapsesPerSegment': 64,\n",
    "        'minThreshold': 10,\n",
    "        'newSynapseCount': 32,\n",
    "        'permanenceDec': 0.1,\n",
    "        'permanenceInc': 0.1},\n",
    " 'anomaly': {\n",
    "   'likelihood': \n",
    "       {#'learningPeriod': int(math.floor(self.probationaryPeriod / 2.0)),\n",
    "        #'probationaryPeriod': self.probationaryPeriod-default_parameters[\"anomaly\"][\"likelihood\"][\"learningPeriod\"],\n",
    "        'probationaryPct': 0.1,\n",
    "        'reestimationPeriod': 100} #These settings are copied from NAB\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i'm gonna try to recode this without \"def main()\" etc\n",
    "- i must explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{   'anomaly': {   'likelihood': {   'probationaryPct': 0.1,\n",
      "                                     'reestimationPeriod': 100}},\n",
      "    'enc': {   'time': {'timeOfDay': (30, 1), 'weekend': 21},\n",
      "               'value': {'resolution': 0.88, 'size': 700, 'sparsity': 0.02}},\n",
      "    'predictor': {'sdrc_alpha': 0.1},\n",
      "    'sp': {   'boostStrength': 3.0,\n",
      "              'columnCount': 1638,\n",
      "              'localAreaDensity': 0.04395604395604396,\n",
      "              'potentialPct': 0.85,\n",
      "              'synPermActiveInc': 0.04,\n",
      "              'synPermConnected': 0.13999999999999999,\n",
      "              'synPermInactiveDec': 0.006},\n",
      "    'tm': {   'activationThreshold': 17,\n",
      "              'cellsPerColumn': 13,\n",
      "              'initialPerm': 0.21,\n",
      "              'maxSegmentsPerCell': 128,\n",
      "              'maxSynapsesPerSegment': 64,\n",
      "              'minThreshold': 10,\n",
      "              'newSynapseCount': 32,\n",
      "              'permanenceDec': 0.1,\n",
      "              'permanenceInc': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print(\"Parameters:\")\n",
    "pprint.pprint(parameters, indent=4)\n",
    "# pprint('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "with open(input_file_path, 'r') as fin:\n",
    "    reader = csv.reader(fin)\n",
    "    headers = next(reader)\n",
    "    next(reader)\n",
    "    next(reader)\n",
    "    for record in reader:\n",
    "        records.append(record) # gymdata.csv is just 2 columns\n",
    "        # dateTime & float(power_consumption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# records # list of dateTime, float\n",
    "# they're coded as strings right now, but no worries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters['enc']['time']['timeOfDay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[\"enc\"][\"time\"][\"weekend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ah, these parameters mean \"how much SDR_space to allocate each variable\"\n",
    "dateEncoder = DateEncoder(\n",
    "    timeOfDay = parameters['enc']['time']['timeOfDay'],\n",
    "    weekend = parameters[\"enc\"][\"time\"][\"weekend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalarEncoderParams = RDSE_Parameters() # random distributed scalar encoder\n",
    "scalarEncoderParams.size       = parameters[\"enc\"][\"value\"][\"size\"]\n",
    "scalarEncoderParams.sparsity   = parameters[\"enc\"][\"value\"][\"sparsity\"]\n",
    "scalarEncoderParams.resolution = parameters[\"enc\"][\"value\"][\"resolution\"]\n",
    "scalarEncoder = RDSE(scalarEncoderParams)\n",
    "encodingWidth = (dateEncoder.size + scalarEncoder.size)\n",
    "enc_info = Metrics( [encodingWidth], 999999999) # wonder what this 2nd parameter is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799999952316284"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarEncoderParams.resolution # ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create spatial pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spParams = parameters['sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SpatialPooler(\n",
    "    inputDimensions            = (encodingWidth,),\n",
    "    columnDimensions           = (spParams[\"columnCount\"],),\n",
    "    potentialPct               = spParams[\"potentialPct\"],\n",
    "    potentialRadius            = encodingWidth,\n",
    "    globalInhibition           = True,\n",
    "    localAreaDensity           = spParams[\"localAreaDensity\"],\n",
    "    synPermInactiveDec         = spParams[\"synPermInactiveDec\"],\n",
    "    synPermActiveInc           = spParams[\"synPermActiveInc\"],\n",
    "    synPermConnected           = spParams[\"synPermConnected\"],\n",
    "    boostStrength              = spParams[\"boostStrength\"],\n",
    "    wrapAround                 = True\n",
    ")\n",
    "sp_info = Metrics(sp.getColumnDimensions(), 999999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there's that \"sp.getColumnDimensions()\" again. very important method, i guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmParams = parameters['tm']\n",
    "tm = TemporalMemory(\n",
    "    columnDimensions          = (spParams[\"columnCount\"],),\n",
    "    cellsPerColumn            = tmParams[\"cellsPerColumn\"],\n",
    "    activationThreshold       = tmParams[\"activationThreshold\"],\n",
    "    initialPermanence         = tmParams[\"initialPerm\"],\n",
    "    connectedPermanence       = spParams[\"synPermConnected\"],\n",
    "    minThreshold              = tmParams[\"minThreshold\"],\n",
    "    maxNewSynapseCount        = tmParams[\"newSynapseCount\"],\n",
    "    permanenceIncrement       = tmParams[\"permanenceInc\"],\n",
    "    permanenceDecrement       = tmParams[\"permanenceDec\"],\n",
    "    predictedSegmentDecrement = 0.0,\n",
    "    maxSegmentsPerCell        = tmParams[\"maxSegmentsPerCell\"],\n",
    "    maxSynapsesPerSegment     = tmParams[\"maxSynapsesPerSegment\"]\n",
    ")\n",
    "tm_info = Metrics( [tm.numberOfCells()], 999999999)\n",
    "# we keep using the 999999999 thing whener we call Metrics(). hmmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TM parameter notes:\n",
    "- cellsPerColumn is very interesting\n",
    "    - if we only had 1, there would be no temporal aspect to the memory\n",
    "    - each cell beyond 1 allows the TM to recognize state_A from another time-step before it\n",
    "    - 4 cells can recognize len=3 state-chains, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup likelihood / anomaly thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anParams = parameters['anomaly']['likelihood']\n",
    "probationaryPeriod = int(math.floor(float(anParams['probationaryPct'])*len(records)))\n",
    "learningPeriod = int(math.floor(probationaryPeriod / 2.0))\n",
    "anomaly_history = AnomalyLikelihood(learningPeriod = learningPeriod,\n",
    "       estimationSamples = probationaryPeriod - learningPeriod,\n",
    "       reestimationPeriod = anParams['reestimationPeriod'])\n",
    "predictor = Predictor(steps=[1,5], alpha=parameters['predictor']['sdrc_alpha'])\n",
    "predictor_resolution = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterate through dataset, recording inputs & outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(steps=[1,5], alpha=parameters['predictor']['sdrc_alpha'])\n",
    "predictor_resolution = 1\n",
    "# changing steps from [1,5] to [1] doesn't fix the learn before infer crash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right, 'records' is a list that stores strings of dateTime & power-floats.\n",
    "- the encoded data is stored... where again?\n",
    "    - it's what we're feeding into the SP + TM, so...\n",
    "    - isn't it \"encoding\"?\n",
    "        - it's an SDR formed by concatenating the encoded-sdrs of dateString & powerFloat\n",
    "        - so this is... yeah, this should be what we feed Predictor.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0][1] # string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternate idea: what if we just run a .learn() cycle once with no infer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "anomaly = []\n",
    "anomalyProb = []\n",
    "predictions = {1: [], 5:[]}\n",
    "for count, record in enumerate(records): # iterate through listified CSV\n",
    "    dateString = datetime.datetime.strptime(record[0], '%m/%d/%y %H:%M')\n",
    "    consumption = float(record[1])\n",
    "    inputs.append(consumption)\n",
    "    \n",
    "    # encoders at work\n",
    "    dateBits = dateEncoder.encode(dateString)\n",
    "    consumptionBits = scalarEncoder.encode(consumption)\n",
    "    # concatenate these bad boys for a composite x,y input\n",
    "    encoding = SDR(encodingWidth).concatenate([consumptionBits, dateBits])\n",
    "    enc_info.addData(encoding) # keep track in metrics\n",
    "    # create an SDR for active columns, same dimensions as SP\n",
    "    activeColumns = SDR(sp.getColumnDimensions())\n",
    "    # hurl input into the pool\n",
    "    sp.compute(encoding, True, activeColumns)\n",
    "    tm_info.addData(tm.getActiveCells().flatten())\n",
    "    # dunno why we add the TM active state before tm.compute(), but i don't know most things\n",
    "    tm.compute(activeColumns, learn=True)\n",
    "    \n",
    "    # let's change things up and try to just let the predictor learn before making a prediction\n",
    "    predictor.learn(count, tm.getActiveCells(), int(round(consumption/predictor_resolution)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## right, that ran. surprising, but it ran. shall we try running the original loop with the same predictor object now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "anomaly = []\n",
    "anomalyProb = []\n",
    "predictions = {1: [], 5:[]}\n",
    "for count, record in enumerate(records): # iterate through listified CSV\n",
    "    dateString = datetime.datetime.strptime(record[0], \"%m/%d/%y %H:%M\") # unstring it\n",
    "    consumption = float(record[1]) # unstring the power value\n",
    "    inputs.append(consumption) # add power to input\n",
    "    \n",
    "    # use encoder: create SDRs for each input value\n",
    "    dateBits = dateEncoder.encode(dateString)\n",
    "    consumptionBits = scalarEncoder.encode(consumption)\n",
    "    \n",
    "    # concatenate these encoded_SDRs into a larger one for pooling\n",
    "    encoding = SDR(encodingWidth).concatenate([consumptionBits, dateBits])\n",
    "    enc_info.addData(encoding) # enc_info is our metrics to keep track of how the encoder fares\n",
    "    \n",
    "    # create SDR to represent active columns. it'll be populated by .compute()\n",
    "    # notably, this activeColumns SDR has same dimensions as spatial pooler\n",
    "    activeColumns = SDR(sp.getColumnDimensions())\n",
    "    \n",
    "    # throw the input into the spatial pool and hope it swims\n",
    "    sp.compute(encoding, True, activeColumns) # we're training, so learn=True\n",
    "    tm_info.addData(tm.getActiveCells().flatten())\n",
    "    ''''''\n",
    "    # gonna have to put a predictor.learn in here somewhere, i believe. maybe i'm incorporating it wrong.\n",
    "#     predictor.learn(count, activeColumns, record[1])\n",
    "    # make prediction, then train the predictor accordingly\n",
    "#     learned = predictor.learn(count, encoding, int(round(float(record[1]))))\n",
    "    predictor.learn(4391+count, tm.getActiveCells(), int(consumption/predictor_resolution))\n",
    "    pdf = predictor.infer( tm.getActiveCells() )\n",
    "    for n in (1,5):\n",
    "        if pdf[n]:\n",
    "            predictions[n].append( np.argmax( pdf[n] ) * predictor_resolution )\n",
    "        else:\n",
    "            predictions[n].append(float('nan'))\n",
    "    \n",
    "    anomalyLikelihood = anomaly_history.anomalyProbability( consumption, tm.anomaly )\n",
    "    anomaly.append(tm.anomaly)\n",
    "    anomalyProb.append(anomalyLikelihood)\n",
    "    \n",
    "#     predictor.learn(count, tm.getActiveCells(), int(consumption/predictor_resolution))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new error! that means progress\n",
    "- it only catches on the last line\n",
    "- wait, that means it just got mad i called predictor.learn twice with the same count\n",
    "- but it crashes with the same error on the first predictor.learn, UNTIL\n",
    "- i changed \"count\" to len(records)+count\n",
    "    - it's gotta keep track of all the SDRs it's been fed with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Input SDR( 1462 )\n",
      "    Sparsity Min/Mean/Std/Max 0.0437757 / 0.0442394 / 0.000319627 / 0.0444596\n",
      "\r",
      "    Activation Frequency Min/Mean/Std/Max 0 / 0.0442397 / 0.0953781 / 0.685391\n",
      "\r",
      "    Entropy 0.700618\n",
      "\r",
      "    Overlap Min/Mean/Std/Max 0 / 0.440847 / 0.088492 / 1\n",
      "\n",
      "Spatial Pooler Mini-Columns SDR( 1638 )\n",
      "    Sparsity Min/Mean/Std/Max inf / 1234.57 / 35.1364 / -inf\n",
      "\r",
      "    Activation Frequency Min/Mean/Std/Max 1234.57 / 1234.59 / 0.0260008 / 1234.57\n",
      "\r",
      "    Entropy 0\n",
      "\r",
      "    Overlap Min/Mean/Std/Max inf / 1234.57 / 35.1364 / -inf\n",
      "Spatial Pooler Connections:\n",
      "    Inputs (1462) ~> Outputs (1638) via Segments (1638)\n",
      "    Segments on Cell Min/Mean/Max 1 / 1 / 1\n",
      "    Potential Synapses on Segment Min/Mean/Max 1243 / 1243 / 1243\n",
      "    Connected Synapses on Segment Min/Mean/Max 54 / 189.177 / 670\n",
      "    Synapses Dead (0.765241%) Saturated (0.0354218%)\n",
      "    Synapses pruned (0%) Segments pruned (0%)\n",
      "    Buffer for destroyed synapses: 0 \t buffer for destr. segments: 0\n",
      "\n",
      "\n",
      "Temporal Memory Cells SDR( 21294 )\n",
      "    Sparsity Min/Mean/Std/Max 0 / 0.00392107 / 0.00336858 / 0.043956\n",
      "\r",
      "    Activation Frequency Min/Mean/Std/Max 0 / 0.00392102 / 0.0292158 / 0.506945\n",
      "\r",
      "    Entropy 0.622192\n",
      "\r",
      "    Overlap Min/Mean/Std/Max 0 / 0.501997 / 0.498361 / 1\n",
      "Temporal Memory Connections:\n",
      "    Inputs (6251) ~> Outputs (21294) via Segments (8349)\n",
      "    Segments on Cell Min/Mean/Max 0 / 0.392082 / 2\n",
      "    Potential Synapses on Segment Min/Mean/Max 32 / 36.1126 / 64\n",
      "    Connected Synapses on Segment Min/Mean/Max 31 / 35.1095 / 64\n",
      "    Synapses Dead (0%) Saturated (0.571031%)\n",
      "    Synapses pruned (0.667255%) Segments pruned (0%)\n",
      "    Buffer for destroyed synapses: 503 \t buffer for destr. segments: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded Input\", enc_info)\n",
    "print(\"\")\n",
    "print(\"Spatial Pooler Mini-Columns\", sp_info)\n",
    "print(str(sp))\n",
    "print(\"\")\n",
    "print(\"Temporal Memory Cells\", tm_info)\n",
    "print(str(tm))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the predictions so that they are aligned with the input they predict.\n",
    "for n_steps, pred_list in predictions.items():\n",
    "    for x in range(n_steps):\n",
    "        pred_list.insert(0, float('nan'))\n",
    "        pred_list.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [nan,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  47,\n",
       "  45,\n",
       "  46,\n",
       "  41,\n",
       "  43,\n",
       "  43,\n",
       "  37,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  14,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  22,\n",
       "  22,\n",
       "  6,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  42,\n",
       "  52,\n",
       "  50,\n",
       "  45,\n",
       "  43,\n",
       "  40,\n",
       "  38,\n",
       "  39,\n",
       "  42,\n",
       "  42,\n",
       "  28,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  13,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  42,\n",
       "  50,\n",
       "  43,\n",
       "  37,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  44,\n",
       "  39,\n",
       "  26,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  17,\n",
       "  22,\n",
       "  7,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  46,\n",
       "  37,\n",
       "  38,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  36,\n",
       "  39,\n",
       "  38,\n",
       "  44,\n",
       "  46,\n",
       "  38,\n",
       "  29,\n",
       "  5,\n",
       "  10,\n",
       "  22,\n",
       "  12,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  42,\n",
       "  39,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  41,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  40,\n",
       "  43,\n",
       "  36,\n",
       "  33,\n",
       "  7,\n",
       "  6,\n",
       "  22,\n",
       "  22,\n",
       "  12,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  42,\n",
       "  42,\n",
       "  39,\n",
       "  45,\n",
       "  41,\n",
       "  41,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  44,\n",
       "  44,\n",
       "  36,\n",
       "  31,\n",
       "  5,\n",
       "  15,\n",
       "  22,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  45,\n",
       "  44,\n",
       "  39,\n",
       "  43,\n",
       "  42,\n",
       "  44,\n",
       "  37,\n",
       "  39,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  41,\n",
       "  38,\n",
       "  38,\n",
       "  13,\n",
       "  9,\n",
       "  22,\n",
       "  20,\n",
       "  11,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  46,\n",
       "  39,\n",
       "  38,\n",
       "  43,\n",
       "  47,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  19,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  25,\n",
       "  43,\n",
       "  41,\n",
       "  48,\n",
       "  49,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  40,\n",
       "  41,\n",
       "  30,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  12,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  31,\n",
       "  39,\n",
       "  45,\n",
       "  39,\n",
       "  38,\n",
       "  41,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  28,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  17,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  19,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  44,\n",
       "  44,\n",
       "  43,\n",
       "  37,\n",
       "  39,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  43,\n",
       "  46,\n",
       "  50,\n",
       "  42,\n",
       "  29,\n",
       "  5,\n",
       "  11,\n",
       "  22,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  6,\n",
       "  18,\n",
       "  37,\n",
       "  41,\n",
       "  37,\n",
       "  44,\n",
       "  47,\n",
       "  47,\n",
       "  41,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  44,\n",
       "  42,\n",
       "  48,\n",
       "  46,\n",
       "  43,\n",
       "  31,\n",
       "  5,\n",
       "  9,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  11,\n",
       "  38,\n",
       "  40,\n",
       "  39,\n",
       "  45,\n",
       "  45,\n",
       "  47,\n",
       "  42,\n",
       "  42,\n",
       "  45,\n",
       "  46,\n",
       "  41,\n",
       "  42,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  31,\n",
       "  5,\n",
       "  8,\n",
       "  17,\n",
       "  18,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  44,\n",
       "  43,\n",
       "  43,\n",
       "  41,\n",
       "  39,\n",
       "  43,\n",
       "  44,\n",
       "  40,\n",
       "  41,\n",
       "  46,\n",
       "  40,\n",
       "  39,\n",
       "  17,\n",
       "  5,\n",
       "  4,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  22,\n",
       "  14,\n",
       "  22,\n",
       "  44,\n",
       "  44,\n",
       "  39,\n",
       "  45,\n",
       "  45,\n",
       "  42,\n",
       "  42,\n",
       "  37,\n",
       "  41,\n",
       "  44,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  37,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  21,\n",
       "  22,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  43,\n",
       "  46,\n",
       "  50,\n",
       "  48,\n",
       "  42,\n",
       "  39,\n",
       "  41,\n",
       "  43,\n",
       "  45,\n",
       "  39,\n",
       "  32,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  15,\n",
       "  21,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  38,\n",
       "  46,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  42,\n",
       "  44,\n",
       "  46,\n",
       "  40,\n",
       "  25,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  15,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  20,\n",
       "  41,\n",
       "  37,\n",
       "  41,\n",
       "  42,\n",
       "  50,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  45,\n",
       "  45,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  10,\n",
       "  17,\n",
       "  19,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  22,\n",
       "  44,\n",
       "  43,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  43,\n",
       "  38,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  42,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  31,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  15,\n",
       "  22,\n",
       "  4,\n",
       "  21,\n",
       "  41,\n",
       "  43,\n",
       "  39,\n",
       "  49,\n",
       "  44,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  41,\n",
       "  37,\n",
       "  40,\n",
       "  39,\n",
       "  44,\n",
       "  38,\n",
       "  36,\n",
       "  31,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  22,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  48,\n",
       "  46,\n",
       "  45,\n",
       "  47,\n",
       "  40,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  41,\n",
       "  37,\n",
       "  14,\n",
       "  5,\n",
       "  17,\n",
       "  20,\n",
       "  18,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  49,\n",
       "  45,\n",
       "  40,\n",
       "  41,\n",
       "  48,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  21,\n",
       "  21,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  44,\n",
       "  42,\n",
       "  47,\n",
       "  48,\n",
       "  41,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  30,\n",
       "  12,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  35,\n",
       "  44,\n",
       "  41,\n",
       "  39,\n",
       "  35,\n",
       "  40,\n",
       "  39,\n",
       "  40,\n",
       "  38,\n",
       "  26,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  16,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  43,\n",
       "  38,\n",
       "  37,\n",
       "  42,\n",
       "  48,\n",
       "  41,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  36,\n",
       "  42,\n",
       "  45,\n",
       "  49,\n",
       "  38,\n",
       "  35,\n",
       "  5,\n",
       "  4,\n",
       "  21,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  20,\n",
       "  42,\n",
       "  37,\n",
       "  36,\n",
       "  40,\n",
       "  46,\n",
       "  42,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  38,\n",
       "  40,\n",
       "  41,\n",
       "  46,\n",
       "  42,\n",
       "  33,\n",
       "  5,\n",
       "  7,\n",
       "  22,\n",
       "  11,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  13,\n",
       "  37,\n",
       "  41,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  45,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  40,\n",
       "  45,\n",
       "  44,\n",
       "  41,\n",
       "  34,\n",
       "  5,\n",
       "  16,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  37,\n",
       "  37,\n",
       "  39,\n",
       "  42,\n",
       "  48,\n",
       "  42,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  38,\n",
       "  36,\n",
       "  39,\n",
       "  46,\n",
       "  43,\n",
       "  40,\n",
       "  14,\n",
       "  7,\n",
       "  22,\n",
       "  19,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  19,\n",
       "  38,\n",
       "  41,\n",
       "  39,\n",
       "  43,\n",
       "  50,\n",
       "  50,\n",
       "  42,\n",
       "  42,\n",
       "  43,\n",
       "  46,\n",
       "  41,\n",
       "  47,\n",
       "  40,\n",
       "  43,\n",
       "  16,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  21,\n",
       "  21,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  14,\n",
       "  40,\n",
       "  44,\n",
       "  56,\n",
       "  58,\n",
       "  46,\n",
       "  45,\n",
       "  43,\n",
       "  47,\n",
       "  47,\n",
       "  43,\n",
       "  28,\n",
       "  18,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  9,\n",
       "  21,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  34,\n",
       "  44,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  47,\n",
       "  42,\n",
       "  25,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  12,\n",
       "  21,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  42,\n",
       "  38,\n",
       "  37,\n",
       "  45,\n",
       "  50,\n",
       "  40,\n",
       "  38,\n",
       "  36,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  40,\n",
       "  46,\n",
       "  45,\n",
       "  39,\n",
       "  31,\n",
       "  5,\n",
       "  9,\n",
       "  17,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  18,\n",
       "  40,\n",
       "  37,\n",
       "  41,\n",
       "  47,\n",
       "  46,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  43,\n",
       "  41,\n",
       "  37,\n",
       "  32,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  14,\n",
       "  22,\n",
       "  8,\n",
       "  19,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  43,\n",
       "  41,\n",
       "  41,\n",
       "  44,\n",
       "  45,\n",
       "  39,\n",
       "  41,\n",
       "  46,\n",
       "  46,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  16,\n",
       "  23,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  44,\n",
       "  44,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  39,\n",
       "  37,\n",
       "  43,\n",
       "  39,\n",
       "  39,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  19,\n",
       "  22,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  34,\n",
       "  43,\n",
       "  38,\n",
       "  36,\n",
       "  44,\n",
       "  46,\n",
       "  41,\n",
       "  38,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  16,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  24,\n",
       "  45,\n",
       "  45,\n",
       "  45,\n",
       "  45,\n",
       "  41,\n",
       "  37,\n",
       "  36,\n",
       "  38,\n",
       "  41,\n",
       "  41,\n",
       "  28,\n",
       "  10,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  38,\n",
       "  45,\n",
       "  43,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  38,\n",
       "  42,\n",
       "  38,\n",
       "  24,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  11,\n",
       "  22,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  45,\n",
       "  42,\n",
       "  36,\n",
       "  41,\n",
       "  49,\n",
       "  41,\n",
       "  39,\n",
       "  39,\n",
       "  43,\n",
       "  42,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  49,\n",
       "  40,\n",
       "  31,\n",
       "  5,\n",
       "  17,\n",
       "  22,\n",
       "  10,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  17,\n",
       "  38,\n",
       "  41,\n",
       "  36,\n",
       "  42,\n",
       "  45,\n",
       "  40,\n",
       "  41,\n",
       "  39,\n",
       "  37,\n",
       "  39,\n",
       "  38,\n",
       "  39,\n",
       "  43,\n",
       "  44,\n",
       "  43,\n",
       "  32,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  13,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  14,\n",
       "  37,\n",
       "  41,\n",
       "  36,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  38,\n",
       "  45,\n",
       "  45,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  7,\n",
       "  21,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  41,\n",
       "  47,\n",
       "  42,\n",
       "  42,\n",
       "  38,\n",
       "  39,\n",
       "  ...],\n",
       " 5: [nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  23,\n",
       "  47,\n",
       "  45,\n",
       "  46,\n",
       "  41,\n",
       "  43,\n",
       "  43,\n",
       "  37,\n",
       "  36,\n",
       "  35,\n",
       "  38,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  14,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  22,\n",
       "  22,\n",
       "  6,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  42,\n",
       "  52,\n",
       "  50,\n",
       "  45,\n",
       "  43,\n",
       "  40,\n",
       "  38,\n",
       "  39,\n",
       "  42,\n",
       "  42,\n",
       "  28,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  13,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  42,\n",
       "  50,\n",
       "  43,\n",
       "  37,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  44,\n",
       "  39,\n",
       "  26,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  17,\n",
       "  22,\n",
       "  7,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  46,\n",
       "  37,\n",
       "  38,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  38,\n",
       "  38,\n",
       "  37,\n",
       "  36,\n",
       "  39,\n",
       "  38,\n",
       "  44,\n",
       "  46,\n",
       "  38,\n",
       "  29,\n",
       "  5,\n",
       "  10,\n",
       "  22,\n",
       "  12,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  42,\n",
       "  39,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  41,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  40,\n",
       "  43,\n",
       "  36,\n",
       "  33,\n",
       "  7,\n",
       "  6,\n",
       "  22,\n",
       "  22,\n",
       "  12,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  42,\n",
       "  42,\n",
       "  39,\n",
       "  45,\n",
       "  41,\n",
       "  41,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  44,\n",
       "  44,\n",
       "  36,\n",
       "  31,\n",
       "  5,\n",
       "  15,\n",
       "  22,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  45,\n",
       "  44,\n",
       "  39,\n",
       "  43,\n",
       "  42,\n",
       "  44,\n",
       "  37,\n",
       "  39,\n",
       "  35,\n",
       "  38,\n",
       "  37,\n",
       "  40,\n",
       "  41,\n",
       "  38,\n",
       "  38,\n",
       "  13,\n",
       "  9,\n",
       "  22,\n",
       "  20,\n",
       "  11,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  46,\n",
       "  39,\n",
       "  38,\n",
       "  43,\n",
       "  47,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  19,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  25,\n",
       "  43,\n",
       "  41,\n",
       "  48,\n",
       "  49,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  40,\n",
       "  41,\n",
       "  30,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  12,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  31,\n",
       "  39,\n",
       "  45,\n",
       "  39,\n",
       "  38,\n",
       "  41,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  28,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  17,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  19,\n",
       "  36,\n",
       "  36,\n",
       "  37,\n",
       "  44,\n",
       "  44,\n",
       "  43,\n",
       "  37,\n",
       "  39,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  43,\n",
       "  46,\n",
       "  50,\n",
       "  42,\n",
       "  29,\n",
       "  5,\n",
       "  11,\n",
       "  22,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  6,\n",
       "  18,\n",
       "  37,\n",
       "  41,\n",
       "  37,\n",
       "  44,\n",
       "  47,\n",
       "  47,\n",
       "  41,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  44,\n",
       "  42,\n",
       "  48,\n",
       "  46,\n",
       "  43,\n",
       "  31,\n",
       "  5,\n",
       "  9,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  11,\n",
       "  38,\n",
       "  40,\n",
       "  39,\n",
       "  45,\n",
       "  45,\n",
       "  47,\n",
       "  42,\n",
       "  42,\n",
       "  45,\n",
       "  46,\n",
       "  41,\n",
       "  42,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  31,\n",
       "  5,\n",
       "  8,\n",
       "  17,\n",
       "  18,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  44,\n",
       "  43,\n",
       "  43,\n",
       "  41,\n",
       "  39,\n",
       "  43,\n",
       "  44,\n",
       "  40,\n",
       "  41,\n",
       "  46,\n",
       "  40,\n",
       "  39,\n",
       "  17,\n",
       "  5,\n",
       "  4,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  22,\n",
       "  14,\n",
       "  22,\n",
       "  44,\n",
       "  44,\n",
       "  39,\n",
       "  45,\n",
       "  45,\n",
       "  42,\n",
       "  42,\n",
       "  37,\n",
       "  41,\n",
       "  44,\n",
       "  39,\n",
       "  40,\n",
       "  40,\n",
       "  37,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  21,\n",
       "  22,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  43,\n",
       "  46,\n",
       "  50,\n",
       "  48,\n",
       "  42,\n",
       "  39,\n",
       "  41,\n",
       "  43,\n",
       "  45,\n",
       "  39,\n",
       "  32,\n",
       "  11,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  15,\n",
       "  21,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  38,\n",
       "  46,\n",
       "  39,\n",
       "  39,\n",
       "  39,\n",
       "  42,\n",
       "  44,\n",
       "  46,\n",
       "  40,\n",
       "  25,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  15,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  20,\n",
       "  41,\n",
       "  37,\n",
       "  41,\n",
       "  42,\n",
       "  50,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  45,\n",
       "  45,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  10,\n",
       "  17,\n",
       "  19,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  22,\n",
       "  44,\n",
       "  43,\n",
       "  41,\n",
       "  43,\n",
       "  44,\n",
       "  43,\n",
       "  38,\n",
       "  40,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  42,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  31,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  15,\n",
       "  22,\n",
       "  4,\n",
       "  21,\n",
       "  41,\n",
       "  43,\n",
       "  39,\n",
       "  49,\n",
       "  44,\n",
       "  42,\n",
       "  40,\n",
       "  38,\n",
       "  41,\n",
       "  37,\n",
       "  40,\n",
       "  39,\n",
       "  44,\n",
       "  38,\n",
       "  36,\n",
       "  31,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  22,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  48,\n",
       "  46,\n",
       "  45,\n",
       "  47,\n",
       "  40,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  41,\n",
       "  37,\n",
       "  14,\n",
       "  5,\n",
       "  17,\n",
       "  20,\n",
       "  18,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  49,\n",
       "  45,\n",
       "  40,\n",
       "  41,\n",
       "  48,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  39,\n",
       "  39,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  35,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  21,\n",
       "  21,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  23,\n",
       "  44,\n",
       "  42,\n",
       "  47,\n",
       "  48,\n",
       "  41,\n",
       "  41,\n",
       "  37,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  30,\n",
       "  12,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  35,\n",
       "  44,\n",
       "  41,\n",
       "  39,\n",
       "  35,\n",
       "  40,\n",
       "  39,\n",
       "  40,\n",
       "  38,\n",
       "  26,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  16,\n",
       "  21,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  43,\n",
       "  38,\n",
       "  37,\n",
       "  42,\n",
       "  48,\n",
       "  41,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  36,\n",
       "  42,\n",
       "  45,\n",
       "  49,\n",
       "  38,\n",
       "  35,\n",
       "  5,\n",
       "  4,\n",
       "  21,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  20,\n",
       "  42,\n",
       "  37,\n",
       "  36,\n",
       "  40,\n",
       "  46,\n",
       "  42,\n",
       "  38,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  38,\n",
       "  40,\n",
       "  41,\n",
       "  46,\n",
       "  42,\n",
       "  33,\n",
       "  5,\n",
       "  7,\n",
       "  22,\n",
       "  11,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  13,\n",
       "  37,\n",
       "  41,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  45,\n",
       "  39,\n",
       "  37,\n",
       "  40,\n",
       "  35,\n",
       "  38,\n",
       "  40,\n",
       "  45,\n",
       "  44,\n",
       "  41,\n",
       "  34,\n",
       "  5,\n",
       "  16,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  37,\n",
       "  37,\n",
       "  39,\n",
       "  42,\n",
       "  48,\n",
       "  42,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  38,\n",
       "  36,\n",
       "  39,\n",
       "  46,\n",
       "  43,\n",
       "  40,\n",
       "  14,\n",
       "  7,\n",
       "  22,\n",
       "  19,\n",
       "  14,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  19,\n",
       "  38,\n",
       "  41,\n",
       "  39,\n",
       "  43,\n",
       "  50,\n",
       "  50,\n",
       "  42,\n",
       "  42,\n",
       "  43,\n",
       "  46,\n",
       "  41,\n",
       "  47,\n",
       "  40,\n",
       "  43,\n",
       "  16,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  21,\n",
       "  21,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  14,\n",
       "  40,\n",
       "  44,\n",
       "  56,\n",
       "  58,\n",
       "  46,\n",
       "  45,\n",
       "  43,\n",
       "  47,\n",
       "  47,\n",
       "  43,\n",
       "  28,\n",
       "  18,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  9,\n",
       "  21,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  34,\n",
       "  44,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  47,\n",
       "  42,\n",
       "  25,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  12,\n",
       "  21,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  42,\n",
       "  38,\n",
       "  37,\n",
       "  45,\n",
       "  50,\n",
       "  40,\n",
       "  38,\n",
       "  36,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  40,\n",
       "  46,\n",
       "  45,\n",
       "  39,\n",
       "  31,\n",
       "  5,\n",
       "  9,\n",
       "  17,\n",
       "  15,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  18,\n",
       "  40,\n",
       "  37,\n",
       "  41,\n",
       "  47,\n",
       "  46,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  36,\n",
       "  38,\n",
       "  38,\n",
       "  39,\n",
       "  43,\n",
       "  41,\n",
       "  37,\n",
       "  32,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  14,\n",
       "  22,\n",
       "  8,\n",
       "  19,\n",
       "  41,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  48,\n",
       "  43,\n",
       "  41,\n",
       "  41,\n",
       "  44,\n",
       "  45,\n",
       "  39,\n",
       "  41,\n",
       "  46,\n",
       "  46,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  16,\n",
       "  23,\n",
       "  20,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  21,\n",
       "  44,\n",
       "  44,\n",
       "  40,\n",
       "  38,\n",
       "  43,\n",
       "  41,\n",
       "  40,\n",
       "  38,\n",
       "  38,\n",
       "  40,\n",
       "  39,\n",
       "  37,\n",
       "  43,\n",
       "  39,\n",
       "  39,\n",
       "  14,\n",
       "  5,\n",
       "  15,\n",
       "  19,\n",
       "  22,\n",
       "  20,\n",
       "  20,\n",
       "  20,\n",
       "  34,\n",
       "  43,\n",
       "  38,\n",
       "  36,\n",
       "  44,\n",
       "  46,\n",
       "  41,\n",
       "  38,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  39,\n",
       "  40,\n",
       "  39,\n",
       "  39,\n",
       "  16,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  24,\n",
       "  45,\n",
       "  45,\n",
       "  45,\n",
       "  45,\n",
       "  41,\n",
       "  37,\n",
       "  36,\n",
       "  38,\n",
       "  41,\n",
       "  41,\n",
       "  28,\n",
       "  10,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  22,\n",
       "  16,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  38,\n",
       "  45,\n",
       "  43,\n",
       "  36,\n",
       "  37,\n",
       "  37,\n",
       "  38,\n",
       "  42,\n",
       "  38,\n",
       "  24,\n",
       "  9,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  11,\n",
       "  22,\n",
       "  15,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  22,\n",
       "  45,\n",
       "  42,\n",
       "  36,\n",
       "  41,\n",
       "  49,\n",
       "  41,\n",
       "  39,\n",
       "  39,\n",
       "  43,\n",
       "  42,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  49,\n",
       "  40,\n",
       "  31,\n",
       "  5,\n",
       "  17,\n",
       "  22,\n",
       "  10,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  17,\n",
       "  38,\n",
       "  41,\n",
       "  36,\n",
       "  42,\n",
       "  45,\n",
       "  40,\n",
       "  41,\n",
       "  39,\n",
       "  37,\n",
       "  39,\n",
       "  38,\n",
       "  39,\n",
       "  43,\n",
       "  44,\n",
       "  43,\n",
       "  32,\n",
       "  5,\n",
       "  13,\n",
       "  22,\n",
       "  13,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  14,\n",
       "  37,\n",
       "  41,\n",
       "  36,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  39,\n",
       "  38,\n",
       "  45,\n",
       "  45,\n",
       "  39,\n",
       "  30,\n",
       "  5,\n",
       "  7,\n",
       "  21,\n",
       "  17,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  18,\n",
       "  38,\n",
       "  36,\n",
       "  37,\n",
       "  41,\n",
       "  47,\n",
       "  ...]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 23,\n",
       " 47,\n",
       " 45,\n",
       " 46,\n",
       " 41,\n",
       " 43,\n",
       " 43,\n",
       " 37,\n",
       " 36,\n",
       " 35,\n",
       " 38,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 14,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 22,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 23,\n",
       " 42,\n",
       " 52,\n",
       " 50,\n",
       " 45,\n",
       " 43,\n",
       " 40,\n",
       " 38,\n",
       " 39,\n",
       " 42,\n",
       " 42,\n",
       " 28,\n",
       " 11,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 13,\n",
       " 22,\n",
       " 13,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 42,\n",
       " 50,\n",
       " 43,\n",
       " 37,\n",
       " 38,\n",
       " 37,\n",
       " 40,\n",
       " 44,\n",
       " 39,\n",
       " 26,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 17,\n",
       " 22,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 46,\n",
       " 37,\n",
       " 38,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 38,\n",
       " 38,\n",
       " 37,\n",
       " 36,\n",
       " 39,\n",
       " 38,\n",
       " 44,\n",
       " 46,\n",
       " 38,\n",
       " 29,\n",
       " 5,\n",
       " 10,\n",
       " 22,\n",
       " 12,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 42,\n",
       " 39,\n",
       " 38,\n",
       " 40,\n",
       " 44,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 39,\n",
       " 39,\n",
       " 37,\n",
       " 40,\n",
       " 40,\n",
       " 43,\n",
       " 36,\n",
       " 33,\n",
       " 7,\n",
       " 6,\n",
       " 22,\n",
       " 22,\n",
       " 12,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 42,\n",
       " 42,\n",
       " 39,\n",
       " 45,\n",
       " 41,\n",
       " 41,\n",
       " 39,\n",
       " 37,\n",
       " 40,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 44,\n",
       " 44,\n",
       " 36,\n",
       " 31,\n",
       " 5,\n",
       " 15,\n",
       " 22,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 45,\n",
       " 44,\n",
       " 39,\n",
       " 43,\n",
       " 42,\n",
       " 44,\n",
       " 37,\n",
       " 39,\n",
       " 35,\n",
       " 38,\n",
       " 37,\n",
       " 40,\n",
       " 41,\n",
       " 38,\n",
       " 38,\n",
       " 13,\n",
       " 9,\n",
       " 22,\n",
       " 20,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 46,\n",
       " 39,\n",
       " 38,\n",
       " 43,\n",
       " 47,\n",
       " 43,\n",
       " 40,\n",
       " 37,\n",
       " 39,\n",
       " 36,\n",
       " 38,\n",
       " 38,\n",
       " 40,\n",
       " 35,\n",
       " 15,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 19,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 25,\n",
       " 43,\n",
       " 41,\n",
       " 48,\n",
       " 49,\n",
       " 42,\n",
       " 40,\n",
       " 38,\n",
       " 43,\n",
       " 40,\n",
       " 41,\n",
       " 30,\n",
       " 11,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 21,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 31,\n",
       " 39,\n",
       " 45,\n",
       " 39,\n",
       " 38,\n",
       " 41,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 28,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 17,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 19,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 44,\n",
       " 44,\n",
       " 43,\n",
       " 37,\n",
       " 39,\n",
       " 41,\n",
       " 37,\n",
       " 39,\n",
       " 43,\n",
       " 46,\n",
       " 50,\n",
       " 42,\n",
       " 29,\n",
       " 5,\n",
       " 11,\n",
       " 22,\n",
       " 15,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 18,\n",
       " 37,\n",
       " 41,\n",
       " 37,\n",
       " 44,\n",
       " 47,\n",
       " 47,\n",
       " 41,\n",
       " 39,\n",
       " 40,\n",
       " 39,\n",
       " 44,\n",
       " 42,\n",
       " 48,\n",
       " 46,\n",
       " 43,\n",
       " 31,\n",
       " 5,\n",
       " 9,\n",
       " 21,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 38,\n",
       " 40,\n",
       " 39,\n",
       " 45,\n",
       " 45,\n",
       " 47,\n",
       " 42,\n",
       " 42,\n",
       " 45,\n",
       " 46,\n",
       " 41,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 39,\n",
       " 31,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 18,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 37,\n",
       " 37,\n",
       " 40,\n",
       " 44,\n",
       " 43,\n",
       " 43,\n",
       " 41,\n",
       " 39,\n",
       " 43,\n",
       " 44,\n",
       " 40,\n",
       " 41,\n",
       " 46,\n",
       " 40,\n",
       " 39,\n",
       " 17,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 22,\n",
       " 14,\n",
       " 22,\n",
       " 44,\n",
       " 44,\n",
       " 39,\n",
       " 45,\n",
       " 45,\n",
       " 42,\n",
       " 42,\n",
       " 37,\n",
       " 41,\n",
       " 44,\n",
       " 39,\n",
       " 40,\n",
       " 40,\n",
       " 37,\n",
       " 15,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 21,\n",
       " 22,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 23,\n",
       " 43,\n",
       " 46,\n",
       " 50,\n",
       " 48,\n",
       " 42,\n",
       " 39,\n",
       " 41,\n",
       " 43,\n",
       " 45,\n",
       " 39,\n",
       " 32,\n",
       " 11,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 15,\n",
       " 21,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 38,\n",
       " 46,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 40,\n",
       " 25,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 15,\n",
       " 21,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 20,\n",
       " 41,\n",
       " 37,\n",
       " 41,\n",
       " 42,\n",
       " 50,\n",
       " 42,\n",
       " 40,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 41,\n",
       " 45,\n",
       " 45,\n",
       " 39,\n",
       " 30,\n",
       " 5,\n",
       " 10,\n",
       " 17,\n",
       " 19,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 44,\n",
       " 43,\n",
       " 41,\n",
       " 43,\n",
       " 44,\n",
       " 43,\n",
       " 38,\n",
       " 40,\n",
       " 40,\n",
       " 39,\n",
       " 39,\n",
       " 42,\n",
       " 41,\n",
       " 40,\n",
       " 38,\n",
       " 31,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 15,\n",
       " 22,\n",
       " 4,\n",
       " 21,\n",
       " 41,\n",
       " 43,\n",
       " 39,\n",
       " 49,\n",
       " 44,\n",
       " 42,\n",
       " 40,\n",
       " 38,\n",
       " 41,\n",
       " 37,\n",
       " 40,\n",
       " 39,\n",
       " 44,\n",
       " 38,\n",
       " 36,\n",
       " 31,\n",
       " 5,\n",
       " 13,\n",
       " 22,\n",
       " 22,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 23,\n",
       " 48,\n",
       " 46,\n",
       " 45,\n",
       " 47,\n",
       " 40,\n",
       " 41,\n",
       " 37,\n",
       " 39,\n",
       " 39,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 43,\n",
       " 41,\n",
       " 37,\n",
       " 14,\n",
       " 5,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 49,\n",
       " 45,\n",
       " 40,\n",
       " 41,\n",
       " 48,\n",
       " 43,\n",
       " 40,\n",
       " 37,\n",
       " 39,\n",
       " 39,\n",
       " 37,\n",
       " 38,\n",
       " 40,\n",
       " 35,\n",
       " 15,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 21,\n",
       " 21,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 23,\n",
       " 44,\n",
       " 42,\n",
       " 47,\n",
       " 48,\n",
       " 41,\n",
       " 41,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 39,\n",
       " 30,\n",
       " 12,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 13,\n",
       " 22,\n",
       " 17,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 35,\n",
       " 44,\n",
       " 41,\n",
       " 39,\n",
       " 35,\n",
       " 40,\n",
       " 39,\n",
       " 40,\n",
       " 38,\n",
       " 26,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 16,\n",
       " 21,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 43,\n",
       " 38,\n",
       " 37,\n",
       " 42,\n",
       " 48,\n",
       " 41,\n",
       " 38,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 36,\n",
       " 42,\n",
       " 45,\n",
       " 49,\n",
       " 38,\n",
       " 35,\n",
       " 5,\n",
       " 4,\n",
       " 21,\n",
       " 15,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 20,\n",
       " 42,\n",
       " 37,\n",
       " 36,\n",
       " 40,\n",
       " 46,\n",
       " 42,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 38,\n",
       " 40,\n",
       " 41,\n",
       " 46,\n",
       " 42,\n",
       " 33,\n",
       " 5,\n",
       " 7,\n",
       " 22,\n",
       " 11,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 37,\n",
       " 41,\n",
       " 38,\n",
       " 43,\n",
       " 48,\n",
       " 45,\n",
       " 39,\n",
       " 37,\n",
       " 40,\n",
       " 35,\n",
       " 38,\n",
       " 40,\n",
       " 45,\n",
       " 44,\n",
       " 41,\n",
       " 34,\n",
       " 5,\n",
       " 16,\n",
       " 22,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 37,\n",
       " 37,\n",
       " 39,\n",
       " 42,\n",
       " 48,\n",
       " 42,\n",
       " 37,\n",
       " 38,\n",
       " 40,\n",
       " 38,\n",
       " 36,\n",
       " 39,\n",
       " 46,\n",
       " 43,\n",
       " 40,\n",
       " 14,\n",
       " 7,\n",
       " 22,\n",
       " 19,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 19,\n",
       " 38,\n",
       " 41,\n",
       " 39,\n",
       " 43,\n",
       " 50,\n",
       " 50,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 46,\n",
       " 41,\n",
       " 47,\n",
       " 40,\n",
       " 43,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 21,\n",
       " 21,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 14,\n",
       " 40,\n",
       " 44,\n",
       " 56,\n",
       " 58,\n",
       " 46,\n",
       " 45,\n",
       " 43,\n",
       " 47,\n",
       " 47,\n",
       " 43,\n",
       " 28,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 21,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 34,\n",
       " 44,\n",
       " 41,\n",
       " 40,\n",
       " 38,\n",
       " 43,\n",
       " 48,\n",
       " 47,\n",
       " 42,\n",
       " 25,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 12,\n",
       " 21,\n",
       " 17,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 21,\n",
       " 42,\n",
       " 38,\n",
       " 37,\n",
       " 45,\n",
       " 50,\n",
       " 40,\n",
       " 38,\n",
       " 36,\n",
       " 41,\n",
       " 40,\n",
       " 38,\n",
       " 40,\n",
       " 46,\n",
       " 45,\n",
       " 39,\n",
       " 31,\n",
       " 5,\n",
       " 9,\n",
       " 17,\n",
       " 15,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 40,\n",
       " 37,\n",
       " 41,\n",
       " 47,\n",
       " 46,\n",
       " 40,\n",
       " 39,\n",
       " 39,\n",
       " 36,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 43,\n",
       " 41,\n",
       " 37,\n",
       " 32,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 14,\n",
       " 22,\n",
       " 8,\n",
       " 19,\n",
       " 41,\n",
       " 37,\n",
       " 38,\n",
       " 43,\n",
       " 48,\n",
       " 43,\n",
       " 41,\n",
       " 41,\n",
       " 44,\n",
       " 45,\n",
       " 39,\n",
       " 41,\n",
       " 46,\n",
       " 46,\n",
       " 39,\n",
       " 30,\n",
       " 5,\n",
       " 16,\n",
       " 23,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 21,\n",
       " 44,\n",
       " 44,\n",
       " 40,\n",
       " 38,\n",
       " 43,\n",
       " 41,\n",
       " 40,\n",
       " 38,\n",
       " 38,\n",
       " 40,\n",
       " 39,\n",
       " 37,\n",
       " 43,\n",
       " 39,\n",
       " 39,\n",
       " 14,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 22,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 34,\n",
       " 43,\n",
       " 38,\n",
       " 36,\n",
       " 44,\n",
       " 46,\n",
       " 41,\n",
       " 38,\n",
       " 37,\n",
       " 38,\n",
       " 43,\n",
       " 39,\n",
       " 40,\n",
       " 39,\n",
       " 39,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 22,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 24,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 41,\n",
       " 37,\n",
       " 36,\n",
       " 38,\n",
       " 41,\n",
       " 41,\n",
       " 28,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 22,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 38,\n",
       " 45,\n",
       " 43,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 42,\n",
       " 38,\n",
       " 24,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 22,\n",
       " 15,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 22,\n",
       " 45,\n",
       " 42,\n",
       " 36,\n",
       " 41,\n",
       " 49,\n",
       " 41,\n",
       " 39,\n",
       " 39,\n",
       " 43,\n",
       " 42,\n",
       " 38,\n",
       " 40,\n",
       " 44,\n",
       " 49,\n",
       " 40,\n",
       " 31,\n",
       " 5,\n",
       " 17,\n",
       " 22,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 17,\n",
       " 38,\n",
       " 41,\n",
       " 36,\n",
       " 42,\n",
       " 45,\n",
       " 40,\n",
       " 41,\n",
       " 39,\n",
       " 37,\n",
       " 39,\n",
       " 38,\n",
       " 39,\n",
       " 43,\n",
       " 44,\n",
       " 43,\n",
       " 32,\n",
       " 5,\n",
       " 13,\n",
       " 22,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 14,\n",
       " 37,\n",
       " 41,\n",
       " 36,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 39,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 39,\n",
       " 38,\n",
       " 45,\n",
       " 45,\n",
       " 39,\n",
       " 30,\n",
       " 5,\n",
       " 7,\n",
       " 21,\n",
       " 17,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 38,\n",
       " 36,\n",
       " 37,\n",
       " 41,\n",
       " 47,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for n in predictions:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this loop sort of makes sense, so the problem is that i'm giving it 0s where it doesn't expect them\n",
    "\n",
    "\n",
    "- for idx, inp in enumerate(inputs): iterate counter,float through list of floats\n",
    "    - for n in predictions: there's 2 values here, 1 and 5 ints.\n",
    "        - val = predictions[1 or 5][counter]\n",
    "        - if not math.isnan(val): # if val isn't nan, because some are nan\n",
    "            - accuracy[1 or 5] += (consumption - predicted_consumption) ** 2\n",
    "            - accuracy_samples[1 or 5] += 1\n",
    "    - for n in sorted(predictions): # for 1 and 5 in predictions:\n",
    "        - accuracy[n] = (accuracy[n] / accuracy_samples[n]) ** 5\n",
    "        - readjust the accuracy based on sample size for RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(anomaly)\n",
    "# right, there's our problem, tm.anomaly only outputted 0s, so no predicted anomalies. hmm.\n",
    "# is it something to do with my added training loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23322332, 0.18041804, 0.05170517, 0.05170517, 0.05060506,\n",
       "       0.25852585, 0.52255226, 0.49944994, 0.50715072, 0.45654565,\n",
       "       0.47744774, 0.48184818, 0.41584158, 0.40264026, 0.39273927,\n",
       "       0.42794279, 0.39823982, 0.40264026, 0.40924092, 0.42024202,\n",
       "       0.15511551, 0.05610561, 0.0550055 , 0.06490649, 0.24752475,\n",
       "       0.24532453, 0.0660066 , 0.05170517, 0.04840484, 0.05280528,\n",
       "       0.25742574, 0.46644664, 0.57205721, 0.55885589, 0.49834983,\n",
       "       0.47964796, 0.44774477, 0.42244224, 0.43894389, 0.47084708,\n",
       "       0.46424642, 0.31463146, 0.12761276, 0.05830583, 0.05940594,\n",
       "       0.05940594, 0.05940594, 0.15071507, 0.24422442, 0.14851485])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy[n]:  0     accuracy_samples[n]:   0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-e5ef0c5097f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy[n]: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"    accuracy_samples[n]:  \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maccuracy_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predictive Error (root-mean-squared): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"steps ahead:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Anomaly Mean: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# calculate predictive accuracy, RMS\n",
    "accuracy         = {1: 0, 5: 0}\n",
    "accuracy_samples = {1: 0, 5: 0}\n",
    "for idx, inp in enumerate(inputs):\n",
    "    for n in predictions: # for each [N]umber of timesteps ahead which was predicted\n",
    "        val = predictions[n][idx]\n",
    "        if not math.isnan(val):\n",
    "            accuracy[n] += (inp - val) ** 2 # RMSE\n",
    "            accuracy_samples[n] += 1\n",
    "    for n in sorted(predictions):\n",
    "        print(\"accuracy[n]: \",accuracy[n], \"    accuracy_samples[n]:  \",accuracy_samples[n])\n",
    "        accuracy[n] = (accuracy[n] / accuracy_samples[n]) ** .5\n",
    "        print(\"Predictive Error (root-mean-squared): \", n, \"steps ahead:\", accuracy[n])\n",
    "    print('Anomaly Mean: ', np.mean(anomaly))\n",
    "    print('Anomaly Std: ', np.std(anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.title(\"Predictions\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power Consumption\")\n",
    "plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "       np.arange(len(inputs)), predictions[1], 'blue',\n",
    "       np.arange(len(inputs)), predictions[5], 'green',)\n",
    "plt.legend(labels=('Input', '1 Step Prediction, Shifted 1 step', '5 Step Prediction, Shifted 5 steps'))\n",
    "# the syntax error was a missing parantheses\n",
    "# good reminder that syntax error on line N usually means you forgot something on line N-1\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"Anomaly Score\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power Consumption\")\n",
    "inputs = np.array(inputs) / max(inputs)\n",
    "plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "       np.arange(len(inputs)), anomaly, 'blue',)\n",
    "plt.legend(labels=('Input', 'Anomaly Score'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alright, what's going on with division by 0 ?\n",
    "- accuracy and accuracy_samples are both dicts where all values are 0\n",
    "    - and we're telling it to divide by the square root of these 0s. cool.\n",
    "    - something is hilariously wrong here.\n",
    "- both these dicts are supposed to be modified in a loop-through-predictions\n",
    "    - so it's not supposed to be dividing be 0. makes more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Encoded Input\", enc_info)\n",
    "print(\"\")\n",
    "print(\"Spatial Pooler Mini-Columns\", sp_info)\n",
    "print(str(sp))\n",
    "print(\"\")\n",
    "print(\"Temporal Memory Cells\", tm_info)\n",
    "print(str(tm))\n",
    "print(\"\"\n",
    "# Shift the predictions so that they are aligned with the input they predict.\n",
    "for n_steps, pred_list in predictions.items():\n",
    "  for x in range(n_steps):\n",
    "      pred_list.insert(0, float('nan'))\n",
    "      pred_list.pop(\n",
    "# Calculate the predictive accuracy, Root-Mean-Squared\n",
    "accuracy         = {1: 0, 5: 0}\n",
    "accuracy_samples = {1: 0, 5: 0\n",
    "for idx, inp in enumerate(inputs):\n",
    "  for n in predictions: # For each [N]umber of time steps ahead which was predicted.\n",
    "    val = predictions[n][ idx ]\n",
    "    if not math.isnan(val):\n",
    "      accuracy[n] += (inp - val) ** 2\n",
    "      accuracy_samples[n] += 1\n",
    "for n in sorted(predictions):\n",
    "  accuracy[n] = (accuracy[n] / accuracy_samples[n]) ** .5\n",
    "  print(\"Predictive Error (RMS)\", n, \"steps ahead:\", accuracy[n]\n",
    "# Show info about the anomaly (mean & std)\n",
    "print(\"Anomaly Mean\", np.mean(anomaly))\n",
    "print(\"Anomaly Std \", np.std(anomaly)\n",
    "# Plot the Predictions and Anomalies.\n",
    "if verbose:\n",
    "  try:\n",
    "    import matplotlib.pyplot as plt\n",
    "  except:\n",
    "    print(\"WARNING: failed to import matplotlib, plots cannot be shown.\")\n",
    "    return -accuracy[5\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.title(\"Predictions\")\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"Power Consumption\")\n",
    "  plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "           np.arange(len(inputs)), predictions[1], 'blue',\n",
    "           np.arange(len(inputs)), predictions[5], 'green',)\n",
    "  plt.legend(labels=('Input', '1 Step Prediction, Shifted 1 step', '5 Step Prediction, Shifted 5 steps')\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.title(\"Anomaly Score\")\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"Power Consumption\")\n",
    "  inputs = np.array(inputs) / max(inputs)\n",
    "  plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "           np.arange(len(inputs)), anomaly, 'blue',)\n",
    "  plt.legend(labels=('Input', 'Anomaly Score'))\n",
    "  plt.show(\n",
    "return -accuracy[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4391"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ah, we're still stuck at the same error as before\n",
    "### something's written wrong, i think - or i've installed something wrong\n",
    "- i can't find anything in the nupic docs regarding predictor.infer\n",
    "- SDRClassifier.infer() needs a list of active indices from output + dict of classification label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some progress:\n",
    "- I realized there's a predictor.learn() at the bottom using count, tm.getActiveCells(), and int(consumption/predictor_resolution))\n",
    "    - this answers a lot of my questions\n",
    "    - now i wonder: why doesn't it work when i copy this line and put it before predictor.infer()?\n",
    "    \n",
    "    \n",
    "- i'm going off johan's example a lot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "htm.bindings.algorithms.Predictor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Predictor in module htm.bindings.algorithms object:\n",
      "\n",
      "class Predictor(pybind11_builtins.pybind11_object)\n",
      " |  The Predictor class does N-Step ahead predictions.\n",
      " |  \n",
      " |  Internally, this class uses Classifiers to associate SDRs with future values.\n",
      " |  This class handles missing datapoints.\n",
      " |  \n",
      " |  Compatibility Note:  This class is the replacement for the old SDRClassifier.\n",
      " |  It no longer provides estimates of the actual value.\n",
      " |  \n",
      " |  Example Usage:\n",
      " |      # Predict 1 and 2 time steps into the future.\n",
      " |  \n",
      " |      # Make a sequence of 4 random SDRs, each SDR has 1000 bits and 2% sparsity.\n",
      " |      sequence = [ SDR( 1000 ).randomize( 0.02 ) for i in range(4) ]\n",
      " |  \n",
      " |      # Make category labels for the sequence.\n",
      " |      labels = [ 4, 5, 6, 7 ]\n",
      " |  \n",
      " |      # Make a Predictor and train it.\n",
      " |      pred = Predictor([ 1, 2 ])\n",
      " |      pred.learn( 0, sequence[0], labels[0] )\n",
      " |      pred.learn( 1, sequence[1], labels[1] )\n",
      " |      pred.learn( 2, sequence[2], labels[2] )\n",
      " |      pred.learn( 3, sequence[3], labels[3] )\n",
      " |  \n",
      " |      # Give the predictor partial information, and make predictions\n",
      " |      # about the future.\n",
      " |      pred.reset()\n",
      " |      A = pred.infer( sequence[0] )\n",
      " |      numpy.argmax( A[1] )  ->  labels[1]\n",
      " |      numpy.argmax( A[2] )  ->  labels[2]\n",
      " |  \n",
      " |      B = pred.infer( sequence[1] )\n",
      " |      numpy.argmax( B[1] )  ->  labels[2]\n",
      " |      numpy.argmax( B[2] )  ->  labels[3]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Predictor\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      __init__(self: htm.bindings.algorithms.Predictor, steps: List[int], alpha: float=0.001) -> None\n",
      " |      \n",
      " |      Argument steps is the number of steps into the future to learn and predict.\n",
      " |      The Predictor accepts a list of steps.\n",
      " |      \n",
      " |      Argument alpha is used to adapt the weight matrix during learning.\n",
      " |      A larger alpha results in faster adaptation to the data.\n",
      " |  \n",
      " |  infer(...)\n",
      " |      infer(self: htm.bindings.algorithms.Predictor, pattern: htm.bindings.sdr.SDR) -> Dict[int, List[float]]\n",
      " |      \n",
      " |      Compute the likelihoods.\n",
      " |      \n",
      " |      Argument pattern is the SDR containing the active input bits.\n",
      " |      \n",
      " |      Returns a dictionary whos keys are prediction steps, and values are PDFs.\n",
      " |      See help(Classifier.infer) for details about PDFs.\n",
      " |  \n",
      " |  learn(...)\n",
      " |      learn(*args, **kwargs)\n",
      " |      Overloaded function.\n",
      " |      \n",
      " |      1. learn(self: htm.bindings.algorithms.Predictor, recordNum: int, pattern: htm.bindings.sdr.SDR, classification: List[int]) -> None\n",
      " |      \n",
      " |      Learn from example data.\n",
      " |      \n",
      " |      Argument recordNum is an incrementing integer for each record.\n",
      " |      Gaps in numbers correspond to missing records.\n",
      " |      \n",
      " |      Argument pattern is the SDR containing the active input bits.\n",
      " |      \n",
      " |      Argument classification is the current category or bucket index.\n",
      " |      This may also be a list for when the input has multiple categories.\n",
      " |      \n",
      " |      2. learn(self: htm.bindings.algorithms.Predictor, recordNum: int, pattern: htm.bindings.sdr.SDR, classification: int) -> None\n",
      " |  \n",
      " |  reset(...)\n",
      " |      reset(self: htm.bindings.algorithms.Predictor) -> None\n",
      " |      \n",
      " |      For use with time series datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why do we call predictor.infer(tm_SDR), then predictor.learn(count, TM_SDR, consumption/predictor_resolution) at each iteration?\n",
    "### because we're trying to make a prediction on each round to see how well we grow over time\n",
    "#### makes sense. but\n",
    "- predictor_resolution is just set to 1.\n",
    "    - so for each data iteration:\n",
    "    - we tell the predictor\n",
    "        - \"assosciate this TM_SDR_output with this consumption level\"\n",
    "            - nevermind for now that consumption is a float and Predictor seems to only want ints\n",
    "        - this makes sense. but why is is giving me an error of \"must call learn before infer\"?\n",
    "        - perhaps it's got nothing to make an inference with since there's no prior training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CHECK FAILED: \"dimensions_ != 0\" Classifier: must call `learn` before `infer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a044384c641d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# make prediction, then train the predictor accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetActiveCells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CHECK FAILED: \"dimensions_ != 0\" Classifier: must call `learn` before `infer`."
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "anomaly = []\n",
    "anomalyProb = []\n",
    "predictions = {1: [], 5:[]}\n",
    "for count, record in enumerate(records): # iterate through listified CSV\n",
    "    dateString = datetime.datetime.strptime(record[0], \"%m/%d/%y %H:%M\") # unstring it\n",
    "    consumption = float(record[1]) # unstring the power value\n",
    "    inputs.append(consumption) # add power to input\n",
    "    \n",
    "    # use encoder: create SDRs for each input value\n",
    "    dateBits = dateEncoder.encode(dateString)\n",
    "    consumptionBits = scalarEncoder.encode(consumption)\n",
    "    \n",
    "    # concatenate these encoded_SDRs into a larger one for pooling\n",
    "    encoding = SDR(encodingWidth).concatenate([consumptionBits, dateBits])\n",
    "    enc_info.addData(encoding) # enc_info is our metrics to keep track of how the encoder fares\n",
    "    \n",
    "    # create SDR to represent active columns. it'll be populated by .compute()\n",
    "    # notably, this activeColumns SDR has same dimensions as spatial pooler\n",
    "    activeColumns = SDR(sp.getColumnDimensions())\n",
    "    \n",
    "    # throw the input into the spatial pool and hope it swims\n",
    "    sp.compute(encoding, True, activeColumns) # we're training, so learn=True\n",
    "    tm_info.addData(tm.getActiveCells().flatten())\n",
    "    \n",
    "    \n",
    "    tm.compute(activeColumns, learn=True)\n",
    "    \n",
    "    # make prediction, then train the predictor accordingly\n",
    "#     predictor.learn(activeColumns)\n",
    "    pdf = predictor.infer( tm.getActiveCells() )\n",
    "    for n in (1,5):\n",
    "        if pdf[n]:\n",
    "            predictions[n].append( np.argmax( pdf[n] ) * predictor_resolution )\n",
    "        else:\n",
    "            predictions[n].append(float('nan'))\n",
    "    \n",
    "    anomalyLikelihood = anomaly_history.anomalyProbability( consumption, tm.anomaly )\n",
    "    anomaly.append(tm.anomaly)\n",
    "    anomalyProb.append(anomalyLikelihood)\n",
    "    \n",
    "    predictor.learn(count, tm.getActiveCells(), int(consumption/predictor_resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for n in (1,5):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information & statistics about the state of the HTM.\n",
    "print(\"Encoded Input\", enc_info)\n",
    "print(\"\")\n",
    "print(\"Spatial Pooler Mini-Columns\", sp_info)\n",
    "print(str(sp))\n",
    "print(\"\")\n",
    "print(\"Temporal Memory Cells\", tm_info)\n",
    "print(str(tm))\n",
    "print(\"\"\n",
    "# Shift the predictions so that they are aligned with the input they predict.\n",
    "for n_steps, pred_list in predictions.items():\n",
    "  for x in range(n_steps):\n",
    "      pred_list.insert(0, float('nan'))\n",
    "      pred_list.pop(\n",
    "# Calculate the predictive accuracy, Root-Mean-Squared\n",
    "accuracy         = {1: 0, 5: 0}\n",
    "accuracy_samples = {1: 0, 5: 0\n",
    "for idx, inp in enumerate(inputs):\n",
    "  for n in predictions: # For each [N]umber of time steps ahead which was predicted.\n",
    "    val = predictions[n][ idx ]\n",
    "    if not math.isnan(val):\n",
    "      accuracy[n] += (inp - val) ** 2\n",
    "      accuracy_samples[n] += 1\n",
    "for n in sorted(predictions):\n",
    "  accuracy[n] = (accuracy[n] / accuracy_samples[n]) ** .5\n",
    "  print(\"Predictive Error (RMS)\", n, \"steps ahead:\", accuracy[n]\n",
    "# Show info about the anomaly (mean & std)\n",
    "print(\"Anomaly Mean\", np.mean(anomaly))\n",
    "print(\"Anomaly Std \", np.std(anomaly)\n",
    "# Plot the Predictions and Anomalies.\n",
    "if verbose:\n",
    "  try:\n",
    "    import matplotlib.pyplot as plt\n",
    "  except:\n",
    "    print(\"WARNING: failed to import matplotlib, plots cannot be shown.\")\n",
    "    return -accuracy[5\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.title(\"Predictions\")\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"Power Consumption\")\n",
    "  plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "           np.arange(len(inputs)), predictions[1], 'blue',\n",
    "           np.arange(len(inputs)), predictions[5], 'green',)\n",
    "  plt.legend(labels=('Input', '1 Step Prediction, Shifted 1 step', '5 Step Prediction, Shifted 5 steps')\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.title(\"Anomaly Score\")\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"Power Consumption\")\n",
    "  inputs = np.array(inputs) / max(inputs)\n",
    "  plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "           np.arange(len(inputs)), anomaly, 'blue',)\n",
    "  plt.legend(labels=('Input', 'Anomaly Score'))\n",
    "  plt.show(\n",
    "return -accuracy[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "47.429px",
    "left": "811.747px",
    "top": "53.4233px",
    "width": "160.98px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
