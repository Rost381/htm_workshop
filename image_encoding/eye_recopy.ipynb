{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#image-->-SDR-with-ChannelEncoder\" data-toc-modified-id=\"image-->-SDR-with-ChannelEncoder-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>image -&gt; SDR with ChannelEncoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#sim\" data-toc-modified-id=\"sim-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>sim</a></span></li><li><span><a href=\"#existing-image_encoders\" data-toc-modified-id=\"existing-image_encoders-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>existing image_encoders</a></span></li><li><span><a href=\"#sparsity-&amp;-color-channels:\" data-toc-modified-id=\"sparsity-&amp;-color-channels:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>sparsity &amp; color channels:</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image -> SDR with ChannelEncoder\n",
    "- how does the ChannelEncoder work?\n",
    "- assigns random range to each bit of output SDR\n",
    "    - each bit becomes active if corresponding input falls within its range\n",
    "    - random ranges: each bit represents a different thing\n",
    "        - even if it mostly overlaps with other comparable bits\n",
    "        - redundant bits add meaning\n",
    "- to encode SDRS:\n",
    "    - 1) every bit of info represents a range of possible values\n",
    "    - for every input, multiple bits activate in SDR\n",
    "- so: each output bit is inaccurate and redundant\n",
    "- ChannelEncoder makes every output bit receptive to unique (random) range of inputs,\n",
    "    - uniformly distributed throughout input space\n",
    "    - has more representational power than if many bits represented identical inp ranges\n",
    "## sim\n",
    "- semantic similarity is when 2 similar inputs have similar SDRs\n",
    "    - channelEnc sem_sim:\n",
    "        - SDR bits respond to range of inp vals\n",
    "        - topology allows nearby bits to represent similar things\n",
    "        \n",
    "## existing image_encoders\n",
    "- many use thresholds on real pixel_value input data -> convert output into Boolean\n",
    "    - (MNIST assigning np.avg>X to enc.dense)\n",
    "- this encoder uses 2 thresholds to form ranges, referred to as \"bins\"\n",
    "    - small change in inp_val could cause some outputs to change\n",
    "    - large change in inp_val could cause all outputs to change\n",
    "    - output_bit_sensitivity (semantic similarity) determined by bin sizes\n",
    "- bin_sizes determined by sparsity:\n",
    "    - assuming inputs distributed in uniform random way throughout input range\n",
    "    - bin_size determines probability that input value falls inside of bin (bigger bucket, more raindrops)\n",
    "        - so sparsity is related to size of bins = sparsity related to amount_semantic_similarity\n",
    "        - this holds true for all bin-based encoders that convert numbers into binary bits\n",
    "- ChannelEnc relies on topology in input image:\n",
    "    - \"adjacent pixels in input are likely to show the same thing\"\n",
    "    - if area of output SDR can't represent a color b/c did not generate the bins necessary\n",
    "    - then it might still be near a pixel which does represent the color\n",
    "    - if less than one active output bits per input pixel (smaller SDR_length than pixel_vector_length):\n",
    "        - multiple close-together output_bits can \"collaborate\" to represent input\n",
    "    - if output bit changes in response to small input change, some semantic_sim is lost\n",
    "    - topology allows nearby outputs to represent the same thing\n",
    "        - since each output uses random bins, they won't all change when input hits single threshold (power of randomly-determined bins)\n",
    "## sparsity & color channels:\n",
    "- to encode color imgs:\n",
    "    - create separate encoders for each color channel\n",
    "    - recombine output sdrs into single big SDR by... multiplying them together\n",
    "        - not concatenating\n",
    "    - multiplication = logical \"and\" here\n",
    "    - combined SDRs sparsity is different\n",
    "        -fraction of active_bits in combined SDR is product of fraction of bits active in all input SDRs\n",
    "        - encoder with 8bits/pixel and sparsity of 1/8:\n",
    "            - create 3 encoders with 8bits/pixel and sparsity of 1/2\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "# some errors on importing cv2.bioinspired\n",
    "# i had to uninstall my opencv package then reinstall as 'pip install opencv-contrib-python'\n",
    "from htm.bindings.sdr import SDR\n",
    "\n",
    "\n",
    "def __init__(self, input_shape, num_samples, sparsity,\n",
    "    dtype       = np.float64,\n",
    "    drange      = range(0,1),\n",
    "    wrap        = False):\n",
    "#     \"\"\"\n",
    "#     Argument input_shape is tuple of dimensions for each input frame.\n",
    "\n",
    "#     Argument num_samples is number of bits in the output SDR which will\n",
    "#              represent each input number, this is the added data depth.\n",
    "\n",
    "#     Argument sparsity is fraction of output which on average will be active.\n",
    "#              This is also the fraction of the input spaces which (on \n",
    "#              average) each bin covers.\n",
    "\n",
    "#     Argument dtype is numpy data type of channel.\n",
    "\n",
    "#     Argument drange is a range object or a pair of values representing the \n",
    "#              range of possible channel values.\n",
    "\n",
    "#     Argument wrap ... default is False.\n",
    "#              This supports modular input spaces and ranges which wrap\n",
    "#              around. It does this by rotating the inputs by a constant\n",
    "#              random amount which hides where the discontinuity in ranges is.\n",
    "#              No ranges actually wrap around the input space.\n",
    "#     \"\"\"\n",
    "    self.input_shape  = tuple(input_shape)\n",
    "    self.num_samples  = int(round(num_samples))\n",
    "    self.sparsity     = sparsity\n",
    "    self.dimensions   = self.input_shape + (self.num_samples,) # output shape\n",
    "    self.size         = np.prod(self.dimensions)\n",
    "    self.dtype        = dtype\n",
    "    self.drange       = drange\n",
    "    self.len_drange   = max(drange) - min(drange)\n",
    "    self.wrap         = bool(wrap)\n",
    "    if self.wrap:\n",
    "        # Each bit responds to a range of input values, length of range is 2*Radius.\n",
    "        radius        = self.len_drange * self.sparsity / 2\n",
    "        self.offsets  = np.random.uniform(0, self.len_drange, self.input_shape)\n",
    "        self.offsets  = np.array(self.offsets, dtype=self.dtype)\n",
    "        # If wrapping is enabled then don't generate ranges which will be\n",
    "        # truncated near the edges.\n",
    "        centers = np.random.uniform(min(self.drange) + radius,\n",
    "                                    max(self.drange) - radius,\n",
    "                                    size=self.dimensions)\n",
    "    else:\n",
    "        # Buckets near the edges of the datarange are OK.  They will not\n",
    "        # respond to a full range of input values but are needed to\n",
    "        # represent the bits at the edges of the data range.\n",
    "        #\n",
    "        # Expand the data range and create bits which will encode for the\n",
    "        # edges of the datarange to ensure a resonable sparsity at the\n",
    "        # extremes of the data ragne.  Increase the size of all of the\n",
    "        # buckets to accomidate for the extra area being represented.\n",
    "        M = .95 # Maximum fraction of bucket-size outside of the true data range to allocate buckets.\n",
    "        len_pad_drange = self.len_drange / (1 - M * self.sparsity)\n",
    "        extra_space    = (len_pad_drange - self.len_drange) / 2\n",
    "        pad_drange     = (min(self.drange) - extra_space, max(self.drange) + extra_space)\n",
    "        radius         = len_pad_drange * self.sparsity / 2\n",
    "        centers = np.random.uniform(min(pad_drange),\n",
    "                                    max(pad_drange),\n",
    "                                    size=self.dimensions)\n",
    "    # Make the lower and upper bounds of the ranges.\n",
    "    low  = np.clip(centers - radius, min(self.drange), max(self.drange))\n",
    "    high = np.clip(centers + radius, min(self.drange), max(self.drange))\n",
    "    self.low  = np.array(low, dtype=self.dtype)\n",
    "    self.high = np.array(high, dtype=self.dtype)\n",
    "\n",
    "def encode(self, img):\n",
    "#     \"\"\"\n",
    "#     Argument img - ndarray\n",
    "#     Returns a SDR\n",
    "#     \"\"\"\n",
    "    #assert(isinstance(inp, SDR)) #TODO make Channel take SDR as input too\n",
    "    #img = np.ndarray(inp.dense).reshape(self.input_shape)\n",
    "    assert(img.shape == self.input_shape)\n",
    "    assert(img.dtype == self.dtype)\n",
    "    if self.wrap:\n",
    "        img += self.offsets\n",
    "        # Technically this should subtract min(drange) before doing modulus\n",
    "        # but the results should also be indistinguishable B/C of the random\n",
    "        # offsets.  Min(drange) effectively becomes part of the offset.\n",
    "        img %= self.len_drange\n",
    "        img += min(self.drange)\n",
    "    img = img.reshape(img.shape + (1,))\n",
    "    img = np.logical_and(self.low <= img, img <= self.high)\n",
    "    enc = SDR(self.dimensions)\n",
    "    enc.dense = img\n",
    "    return enc\n",
    "\n",
    "\n",
    "class Eye:\n",
    "# \"\"\"\n",
    "# Optic sensor with central fovae.\n",
    "# Simulates functionality of eye's retinal parvocellular(P-cells),\n",
    "# and magnocellular(M-cells) pathways, at the saccadic steps. \n",
    "\n",
    "# On high level, \n",
    "# magno cells: \n",
    "#   - detect change in temporal information in the image, ie motion \n",
    "#     detection, video processing tasks, ... \n",
    "# parvo cells: \n",
    "#   - detect color, shape information in the (static) image. Useful\n",
    "#     for image classification, etc. \n",
    "# For more details see: \n",
    "# https://foundationsofvision.stanford.edu/chapter-5-the-retinal-representation/#visualinformation\n",
    "\n",
    "# #TODO the motion-control of \"where to look at\" is not fully researched \n",
    "# and covered by this code. You need to manually control the positions \n",
    "# of the eye/sensor (where it looks at) at the level of saccades. \n",
    "\n",
    "\n",
    "# Attribute roi ... The most recent view, kept as a attribute.\n",
    "# Attribute parvo_sdr ... SDR with parvocellular pathway (color)\n",
    "# Attribute magno_sdr ... SDR with magnocellular pathway (movement) \n",
    "\n",
    "# The following three attributes control where the eye is looking within\n",
    "# the image.  They are Read/Writable.\n",
    "#   Note: (X,Y,scale,rotation) require manual control by the user, as in the brain\n",
    "#   this is part of the Motor-Control, which is not in the scope of this encoder. \n",
    "\n",
    "# Attribute position     (X, Y) coords of eye center within image\n",
    "#   (wrt [0,0] corner of the image). Default starting position is the center\n",
    "#   of the image. \n",
    "# Attribute orientation  ... units are radians, the rotation of the sensor\n",
    "#   (wrt the image)\n",
    "# Attribute scale        ... The scale controls the distance between the eye\n",
    "#   and the image (scale is similar to distance on Z-axis). \n",
    "#   Note: In experiments you typically need to manually tune the `scale` for the dataset, \n",
    "#   to find a reasonable value through trial and error.\n",
    "#   More explanation: \"When you look at a really big image, you need to take\n",
    "#   a few steps back to be able to see the whole thing. The scale parameter \n",
    "#   allows the eye to do just that, walk forwards and backwards from the image,\n",
    "#   to find good place to view it from.\"\n",
    "# \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        output_diameter   = 200, # output SDR size is diameter^2\n",
    "        sparsityParvo     = 0.2,\n",
    "        sparsityMagno     = 0.025,\n",
    "        color             = True,):\n",
    "    #     \"\"\"\n",
    "    #     Argument output_diameter is size of output ... output is a \n",
    "    #         field of view (image) with circular shape. Default 200. \n",
    "    #         `parvo/magno_sdr` size is `output_diameter^2`\n",
    "    #     Argument `sparsityParvo` - sparsity of parvo-cellular pathway of the eye.\n",
    "    #         As a simplification, \"parvo\" cells (P-cells) represent colors, static \n",
    "    #         object's properties (shape,...) and are used for image classification. \n",
    "    #         For biologically accurate details see eg. \n",
    "    #         https://foundationsofvision.stanford.edu/chapter-5-the-retinal-representation/\n",
    "    #         Note: biologically, the ratio between P/M-cells is about 8(P):1(M):(1 rest), see\n",
    "    #         https://www.pnas.org/content/94/11/5900\n",
    "    #     Argument `sparsityMagno` - sparsity of the magno-cellular (M-cells) pathway, which\n",
    "    #         transfers (higly) temporal information in the visual data, as use \"used\" for\n",
    "    #         motion detection and motion tracking, video processing.\n",
    "    #         For details see @param `sparsityParvo`.\n",
    "    #         TODO: output of M-cells should be processed on a fast TM.\n",
    "    #     Argument color: use color vision (requires P-cells > 0), default true.\n",
    "    #     \"\"\"\n",
    "        self.output_diameter   = output_diameter\n",
    "        # Argument resolution_factor is used to expand the sensor array so that\n",
    "        # the fovea has adequate resolution.  After log-polar transform image\n",
    "        # is reduced by this factor back to the output_diameter.\n",
    "        self.resolution_factor = 2\n",
    "        self.retina_diameter   = int(self.resolution_factor * output_diameter)\n",
    "        # Argument fovea_scale  ... proportion of the image (ROI) which will be covered (seen) by\n",
    "        # high-res fovea (parvo pathway)\n",
    "        self.fovea_scale       = 0.177\n",
    "        assert(output_diameter % 2 == 0) # Diameter must be an even number.\n",
    "        assert(self.retina_diameter % 2 == 0) # (Resolution Factor X Diameter) must be an even number.\n",
    "        assert(sparsityParvo >= 0 and sparsityParvo <= 1.0)\n",
    "        if sparsityParvo > 0:\n",
    "            assert(sparsityParvo * (self.retina_diameter **2) > 0)\n",
    "        self.sparsityParvo = sparsityParvo\n",
    "        assert(sparsityMagno >= 0 and sparsityMagno <= 1.0)\n",
    "        if sparsityMagno > 0:\n",
    "            assert(sparsityMagno * (self.retina_diameter **2) > 0)\n",
    "        self.sparsityMagno = sparsityMagno\n",
    "        if color is True:\n",
    "            assert(sparsityParvo > 0)\n",
    "        self.color = color\n",
    "    \n",
    "    \n",
    "        self.retina = cv2.bioinspired.Retina_create(\n",
    "            inputSize            = (self.retina_diameter, self.retina_diameter),\n",
    "            colorMode            = color,\n",
    "            colorSamplingMethod  = cv2.bioinspired.RETINA_COLOR_BAYER,\n",
    "            useRetinaLogSampling = True,)\n",
    "    \n",
    "        print(self.retina.printSetup())\n",
    "        print()\n",
    "    \n",
    "        if sparsityParvo > 0:\n",
    "            dims = (output_diameter, output_diameter)\n",
    "        \n",
    "            sparsityP_ = sparsityParvo\n",
    "            if color is True: \n",
    "                dims = (output_diameter, output_diameter, 3,) #3 for RGB color channels\n",
    "        \n",
    "                # The reason the parvo-cellular has `3rd-root of the sparsity` is that there are three color channels (RGB), \n",
    "                # each of which is encoded separately and then combined. The color channels are combined with a logical AND, \n",
    "                # which on average reduces the sparsity.\n",
    "                # This same principal applies to any time you combine two encoders with a logical bit-wise AND, the final combined\n",
    "                # sparsity would be `sparsity^n`, hence the cubic root for 3 dims: \n",
    "                sparsityP_ = sparsityParvo ** (1/3.)\n",
    "        \n",
    "            self.parvo_enc = ChannelEncoder(\n",
    "                                input_shape = dims,\n",
    "                                num_samples = 1, \n",
    "                                sparsity = sparsityP_,\n",
    "                                dtype=np.uint8, drange=[0, 255,])\n",
    "        else:\n",
    "            self.parvo_enc = None\n",
    "    \n",
    "        if sparsityMagno > 0:\n",
    "            self.magno_enc = ChannelEncoder(\n",
    "                            input_shape = (output_diameter, output_diameter),\n",
    "                            num_samples = 1, \n",
    "                            sparsity = sparsityMagno,\n",
    "                            dtype=np.uint8, drange=[0, 255],)\n",
    "        else:\n",
    "            self.magno_enc = None\n",
    "    \n",
    "        ## output variables:\n",
    "        self.dimensions = (output_diameter, output_diameter,)\n",
    "        self.size       = np.prod(self.dimensions)\n",
    "        self.image      = None # the current input RGB image\n",
    "        self.roi        = np.zeros(self.dimensions) # self.image cropped to region of interest, what encoder processes (\"sees\")\n",
    "        self.parvo_img  = None # output visualization of parvo/magno cells\n",
    "        self.magno_img  = None\n",
    "        self.parvo_sdr  = SDR(self.dimensions) # parvo/magno cellular representation (SDR)\n",
    "        self.magno_sdr  = SDR(self.dimensions)\n",
    "    \n",
    "        ## motor-control variables (must be user specified)\n",
    "        self.position   = (0,0) # can use self.center_view(), self.random_view()\n",
    "        self.scale      = 1.0 # represents \"zoom\" aka distance from the object/image \n",
    "        self.orientation= 0 # angle between image/object and camera, in deg\n",
    "    \n",
    "    \n",
    "    def _new_image(self, image):\n",
    "    #     \"\"\"\n",
    "    #     Argument image ...\n",
    "    #         If String, will load image from file path.\n",
    "    #         If numpy.ndarray, will attempt to cast to correct data type and\n",
    "    #             dimensions.\n",
    "    \n",
    "    #     For demo, run: \n",
    "    #     python py/htm/encoders/eye.py py/tests/encoders/ronja_the_cat.jpg\n",
    "    #     \"\"\"\n",
    "        # Load image if needed.\n",
    "        if isinstance(image, str):\n",
    "            self.image = cv2.imread(image)\n",
    "            self.image = cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            self.image = image\n",
    "        # Get the image into the right format.\n",
    "        assert(isinstance(self.image, np.ndarray))\n",
    "        # Ensure there are three color channels.\n",
    "        if len(self.image.shape) == 2 or self.image.shape[2] == 1:\n",
    "            self.image = np.dstack([self.image] * 3)\n",
    "        # Drop the alpha channel if present.\n",
    "        elif self.image.shape[2] == 4:\n",
    "            self.image = self.image[:,:,:3]\n",
    "        # Sanity checks.\n",
    "        assert(len(self.image.shape) == 3)\n",
    "        assert(self.image.shape[2] == 3) # Color images only.\n",
    "        self.reset()\n",
    "        self.center_view()\n",
    "        self.roi = None\n",
    "        assert(min(self.image.shape[:2]) >= self.retina_diameter)\n",
    "        return self.image\n",
    "    \n",
    "    \n",
    "    def center_view(self):\n",
    "    #     \"\"\"Center the view over the image\"\"\"\n",
    "        self.orientation = 0\n",
    "        self.position    = (self.image.shape[0]/2., self.image.shape[1]/2.)\n",
    "        self.scale       = np.min(np.divide(self.image.shape[:2], self.retina_diameter))\n",
    "        self.roi = None #changing center breaks prev ROI\n",
    "    \n",
    "    def randomize_view(self, scale_range=None):\n",
    "    #     \"\"\"Set the eye's view point to a random location\"\"\"\n",
    "        if scale_range is None:\n",
    "            scale_range = [2, min(self.image.shape[:2]) / self.retina_diameter]\n",
    "        assert(len(scale_range) == 2)\n",
    "        self.orientation = random.uniform(0, 2 * math.pi)\n",
    "        self.scale       = random.uniform(min(scale_range), max(scale_range))\n",
    "        roi_radius       = self.scale * self.retina_diameter / 2\n",
    "        self.position    = [random.uniform(roi_radius, dim - roi_radius)\n",
    "                                 for dim in self.image.shape[:2]]\n",
    "        self.roi = None\n",
    "    \n",
    "    \n",
    "    def _crop_roi(image, position, diameter, scale):\n",
    "    #     \"\"\"\n",
    "    #     Crop to Region Of Interest (ROI) which contains the whole field of view.\n",
    "    #     Adds a black circular boarder to mask out areas which the eye can't see.\n",
    "    \n",
    "    #     Note: size of the ROI is (eye.output_diameter * eye.resolution_factor).\n",
    "    #     Note: the circular boarder is actually a bit too far out, playing with\n",
    "    #       eye.fovea_scale can hide areas which this ROI image will show.\n",
    "    \n",
    "    #     Arguments: eye.scale, eye.position, eye.image\n",
    "    \n",
    "    #     Returns RGB image (diameter * diameter, but effectively cropped to an \n",
    "    #       inner circle - FOV). \n",
    "    \n",
    "    #     See also, @see make_roi_pretty()\n",
    "    #     \"\"\"\n",
    "        assert(isinstance(image, np.ndarray))\n",
    "        assert(diameter > 0)\n",
    "        assert(scale > 0)\n",
    "    \n",
    "        r     = int(round(scale * diameter / 2))\n",
    "        assert(r > 0)\n",
    "        x, y  = position\n",
    "        x     = int(round(x))\n",
    "        y     = int(round(y))\n",
    "        x_max, y_max, color_depth = image.shape\n",
    "    \n",
    "        # Find the boundary of the ROI and slice out the image.\n",
    "        x_low  = max(0, x-r)\n",
    "        x_high = min(x_max, x+r)\n",
    "        y_low  = max(0, y-r)\n",
    "        y_high = min(y_max, y+r)\n",
    "        image_slice = image[x_low : x_high, y_low : y_high]\n",
    "    \n",
    "        # Make the ROI and insert the image into it.\n",
    "        roi = np.zeros((2*r, 2*r, 3,), dtype=np.uint8)\n",
    "        if x-r < 0:\n",
    "            x_offset = abs(x-r)\n",
    "        else:\n",
    "            x_offset = 0\n",
    "        if y-r < 0:\n",
    "            y_offset = abs(y-r)\n",
    "        else:\n",
    "            y_offset = 0\n",
    "        x_shape, y_shape, color_depth = image_slice.shape\n",
    "        roi[x_offset:x_offset+x_shape, y_offset:y_offset+y_shape] = image_slice\n",
    "    \n",
    "        # Rescale the ROI to remove the scaling effect.\n",
    "        roi = cv2.resize(roi, (diameter, diameter),  interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "        # Mask out areas the eye can't see by drawing a circle boarder.\n",
    "        # this represents the \"shape\" of the sensor/eye (comment out to leave rectangural)\n",
    "        center = int(roi.shape[0] / 2)\n",
    "        circle_mask = np.zeros(roi.shape, dtype=np.uint8)\n",
    "        cv2.circle(circle_mask, (center, center), center, thickness = -1, color=(255,255,255))\n",
    "        roi = np.minimum(roi, circle_mask)\n",
    "    \n",
    "        return roi\n",
    "    \n",
    "    \n",
    "    def compute(self, img, position=None, rotation=None, scale=None):\n",
    "    #     \"\"\"\n",
    "    #     Argument img - image to load. String/data, see _new_image()\n",
    "    #     Arguments position, rotation, scale: optional, if not None, the self.xxx is overriden\n",
    "    #       with the provided value.\n",
    "    #     Returns tuple (SDR parvo, SDR magno) \n",
    "    #     \"\"\"\n",
    "        self.image = self._new_image(img)\n",
    "        assert(self.image is not None)\n",
    "    \n",
    "        # set position\n",
    "        if position is not None:\n",
    "            self.position = position\n",
    "        if rotation is not None:\n",
    "            self.orientation=rotation\n",
    "        if scale is not None:\n",
    "            self.scale=scale\n",
    "    \n",
    "        # apply field of view (FOV), rotation\n",
    "        self.roi = self.rotate_(self.image, self.orientation) \n",
    "        self.roi = Eye._crop_roi(self.roi, self.position, self.retina_diameter, self.scale)\n",
    "    \n",
    "        # Retina image transforms (Parvo & Magnocellular).\n",
    "        self.retina.run(self.roi)\n",
    "        if self.parvo_enc is not None:\n",
    "            parvo = self.retina.getParvo()\n",
    "        if self.magno_enc is not None:\n",
    "            magno = self.retina.getMagno()\n",
    "    \n",
    "    \n",
    "        # Log Polar Transform.\n",
    "        center = self.retina_diameter / 2\n",
    "        M      = self.retina_diameter * self.fovea_scale\n",
    "        M = min(M, self.output_diameter)\n",
    "        if self.parvo_enc is not None:\n",
    "            parvo = cv2.logPolar(parvo,\n",
    "                               center = (center, center),\n",
    "                               M = M,\n",
    "                               flags = cv2.WARP_FILL_OUTLIERS)\n",
    "            parvo = cv2.resize(parvo,  dsize=(self.output_diameter, self.output_diameter), interpolation = cv2.INTER_CUBIC)\n",
    "            self.parvo_img = parvo\n",
    "    \n",
    "        if self.magno_enc is not None:\n",
    "            magno = cv2.logPolar(magno,\n",
    "                               center = (center, center),\n",
    "                               M = M,\n",
    "                               flags = cv2.WARP_FILL_OUTLIERS)\n",
    "            magno = cv2.resize(magno, dsize=(self.output_diameter, self.output_diameter), interpolation = cv2.INTER_CUBIC)\n",
    "            self.magno_img = magno\n",
    "    \n",
    "        # Encode images into SDRs.\n",
    "        if self.parvo_enc is not None:\n",
    "            p   = self.parvo_enc.encode(parvo).dense\n",
    "            if self.color:\n",
    "                pr, pg, pb = np.dsplit(p, 3)\n",
    "                p   = np.logical_and(np.logical_and(pr, pg), pb)\n",
    "            p   = np.expand_dims(np.squeeze(p), axis=2)\n",
    "            self.parvo_sdr.dense = p.flatten()\n",
    "            assert(len(self.parvo_sdr.sparse) > 0)\n",
    "    \n",
    "        if self.magno_enc is not None:\n",
    "            self.magno_sdr = self.magno_enc.encode(magno)\n",
    "            assert(len(self.magno_sdr.sparse) > 0)\n",
    "    \n",
    "        return (self.parvo_sdr, self.magno_sdr)\n",
    "    \n",
    "    \n",
    "    def _make_roi_pretty(self, roi):\n",
    "        \"\"\"\n",
    "        Makes the eye's view look more presentable.\n",
    "        - Adds 5 dots to the center of the image to show where the fovea is.\n",
    "    \n",
    "        Returns an RGB image.\n",
    "        See _crop_roi()\n",
    "        \"\"\"\n",
    "        assert(roi is not None)\n",
    "    \n",
    "        # Invert 5 pixels in the center to show where the fovea is located.\n",
    "        center = int(roi.shape[0] / 2)\n",
    "        roi[center, center]     = np.full(3, 255) - roi[center, center]\n",
    "        roi[center+2, center+2] = np.full(3, 255) - roi[center+2, center+2]\n",
    "        roi[center-2, center+2] = np.full(3, 255) - roi[center-2, center+2]\n",
    "        roi[center-2, center-2] = np.full(3, 255) - roi[center-2, center-2]\n",
    "        roi[center+2, center-2] = np.full(3, 255) - roi[center+2, center-2]\n",
    "    \n",
    "        # Draw a red circle where fovea (=high resolution parvocellular vision) boundary is\n",
    "        cv2.circle(roi, (center, center), radius=int(self.retina_diameter*self.fovea_scale), color=(255,0,0), thickness=3)\n",
    "    \n",
    "        return roi\n",
    "    \n",
    "    \n",
    "    def rotate_(self, img, angle):\n",
    "    #   \"\"\"\n",
    "    #   rotate the image img, by angle in degrees\n",
    "    #   \"\"\"\n",
    "        assert(isinstance(img, np.ndarray))\n",
    "        angle = angle * 360 / (2 * math.pi)\n",
    "        rows, cols, color_depth = img.shape\n",
    "        M   = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "        return cv2.warpAffine(img, M, (cols,rows))\n",
    "    \n",
    "    \n",
    "    def plot(self, window_name='Eye', delay=1000):\n",
    "        roi = self._make_roi_pretty(self.roi)\n",
    "        cv2.imshow('Region Of Interest', roi)\n",
    "        cv2.imshow('Whole image', self.image)\n",
    "    \n",
    "        if self.sparsityParvo > 0: # parvo enabled\n",
    "            if self.color:\n",
    "                cv2.imshow('Parvocellular', self.parvo_img[:,:,::-1])\n",
    "                cv2.imshow('Parvo retinal representation', self.retina.getParvo()[:,:,::-1])\n",
    "            else:\n",
    "                cv2.imshow('Parvocellular', self.parvo_img)\n",
    "            idx = self.parvo_sdr.dense.astype(np.uint8).reshape(self.output_diameter, self.output_diameter)*255\n",
    "            cv2.imshow('Parvo SDR', idx)\n",
    "    \n",
    "        if self.sparsityMagno > 0: # magno enabled\n",
    "            cv2.imshow('Magnocellular', self.magno_img)\n",
    "            idx = self.magno_sdr.dense.astype(np.uint8).reshape(self.output_diameter, self.output_diameter)*255\n",
    "            cv2.imshow('Magno SDR', idx)\n",
    "    \n",
    "        cv2.waitKey(delay)\n",
    "    \n",
    "    \n",
    "    def small_random_movement(self):\n",
    "        \"\"\"returns small difference in position, rotation, scale.\n",
    "           This is naive \"saccadic\" movements.\n",
    "        \"\"\"\n",
    "        max_change_angle = (2*math.pi) / 100\n",
    "        self.position = (\n",
    "            self.position[0] + random.gauss(1.2, .75),\n",
    "            self.position[1] + random.gauss(1.2, .75),)\n",
    "        self.orientation += random.uniform(-max_change_angle, max_change_angle)\n",
    "        self.scale += random.gauss(0, 0.1)\n",
    "        return (self.position, self.orientation, self.scale)\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.retina.clearBuffers()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_images(path):\n",
    "#     \"\"\" Returns list of all image files found under the given file path. \"\"\"\n",
    "        image_extensions = [\n",
    "            '.bmp',\n",
    "            '.dib',\n",
    "            '.png',\n",
    "            '.jpg',\n",
    "            '.jpeg',\n",
    "            '.jpe',\n",
    "            '.tif',\n",
    "            '.tiff',\n",
    "        ]\n",
    "        images = []\n",
    "        import os\n",
    "        if os.path.isfile(path):\n",
    "            basename, ext = os.path.splitext(path)\n",
    "            if ext.lower() in image_extensions:\n",
    "                images.append( path )\n",
    "        else:\n",
    "            for dirpath, dirnames, filenames in os.walk(path):\n",
    "                for fn in filenames:\n",
    "                    basename, ext = os.path.splitext(fn)\n",
    "                    if ext.lower() in image_extensions:\n",
    "                        images.append( os.path.join(dirpath, fn) )\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'bioinspired'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-00d5fc620ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0msparsityParvo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0msparsityMagno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           color=True)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0meye\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-1a3bf6127c1a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_diameter, sparsityParvo, sparsityMagno, color)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         self.retina = cv2.bioinspired.Retina_create(\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0minputSize\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina_diameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina_diameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mcolorMode\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'bioinspired'"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "# args = argparse.ArgumentParser()\n",
    "# args.add_argument('IMAGE', type=str)\n",
    "# args   = args.parse_args()\n",
    "# images = _get_images( args.IMAGE )\n",
    "# random.shuffle(images)\n",
    "# if not images:\n",
    "#     print('No images found at file path \"%s\"!'%args.IMAGE)\n",
    "# else:\n",
    "import os\n",
    "\n",
    "images = [filepath for filepath in os.getcwd() if '.jpg' in filepath]\n",
    "eye = Eye(output_diameter=200,\n",
    "          sparsityParvo=0.2,\n",
    "          sparsityMagno=0.02,\n",
    "          color=True)\n",
    "for img_path in images:\n",
    "    eye.reset()\n",
    "    eye.fovea_scale = 0.077 #TODO find which value?\n",
    "    #eye.center_view()\n",
    "    eye.position=(400,400)\n",
    "    for i in range(10):\n",
    "        pos,rot,sc = eye.small_random_movement()\n",
    "        (sdrParvo, sdrMagno) = eye.compute(img_path, pos,rot,sc) #TODO derive from Encoder\n",
    "        eye.plot(delay=5000)\n",
    "    print(\"Sparsity parvo: {}\".format(len(eye.parvo_sdr.sparse)/np.product(eye.dimensions)))\n",
    "    print(\"Sparsity magno: {}\".format(len(eye.magno_sdr.sparse)/np.product(eye.dimensions)))\n",
    "print(\"All images seen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'bioinspired' from 'cv2.cv2' (/Users/mark/opt/anaconda3/lib/python3.7/site-packages/cv2/cv2.cpython-37m-darwin.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-625bec8ffe6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbioinspired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'bioinspired' from 'cv2.cv2' (/Users/mark/opt/anaconda3/lib/python3.7/site-packages/cv2/cv2.cpython-37m-darwin.so)"
     ]
    }
   ],
   "source": [
    "# from cv2 import bioinspired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2.bioinspired'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4d8d74a36530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbioinspired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2.bioinspired'"
     ]
    }
   ],
   "source": [
    "# import cv2.bioinspired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'bioinspired'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c7d64aa16515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbioinspired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'bioinspired'"
     ]
    }
   ],
   "source": [
    "cv2.bioinspired # cv2.cv2 has no attribute 'bioinspired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] IMAGE\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument('IMAGE', type=str)\n",
    "    args   = args.parse_args()\n",
    "    images = _get_images( args.IMAGE )\n",
    "    random.shuffle(images)\n",
    "    if not images:\n",
    "        print('No images found at file path \"%s\"!'%args.IMAGE)\n",
    "    else:\n",
    "        eye = Eye(output_diameter=200,\n",
    "                  sparsityParvo=0.2,\n",
    "                  sparsityMagno=0.02,\n",
    "                  color=True)\n",
    "        for img_path in images:\n",
    "            eye.reset()\n",
    "            eye.fovea_scale = 0.077 #TODO find which value?\n",
    "            #eye.center_view()\n",
    "            eye.position=(400,400)\n",
    "            for i in range(10):\n",
    "                pos,rot,sc = eye.small_random_movement()\n",
    "                (sdrParvo, sdrMagno) = eye.compute(img_path, pos,rot,sc) #TODO derive from Encoder\n",
    "                eye.plot(delay=5000)\n",
    "            print(\"Sparsity parvo: {}\".format(len(eye.parvo_sdr.sparse)/np.product(eye.dimensions)))\n",
    "            print(\"Sparsity magno: {}\".format(len(eye.magno_sdr.sparse)/np.product(eye.dimensions)))\n",
    "        print(\"All images seen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0998b6f031d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IMAGE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0margs\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_images\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2501\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2488\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "602.4px",
    "left": "1228.8px",
    "top": "53.6px",
    "width": "307.2px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
